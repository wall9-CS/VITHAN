{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"tMncOeX6pDmB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747362328231,"user_tz":-540,"elapsed":22148,"user":{"displayName":"URP","userId":"16515248769931109428"}},"outputId":"dbbcd297-ba27-4897-95d1-c14fb6f32cc0"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# import\n","import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","import numpy as np\n","import copy\n","import argparse\n","import datetime\n","import time\n","import os\n","import math\n","import random\n","from tqdm import tqdm\n"],"metadata":{"id":"xWGfSBgsm1r2","executionInfo":{"status":"ok","timestamp":1747362335281,"user_tz":-540,"elapsed":3837,"user":{"displayName":"URP","userId":"16515248769931109428"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["# util.py"],"metadata":{"id":"rhEFWjoInTFU"}},{"cell_type":"code","source":["import numpy as np\n","\n","def calculate_rank(score, target, filter_list):\n","\tscore_target = score[target]\n","\tscore[filter_list] = score_target - 1\n","\trank = np.sum(score > score_target) + np.sum(score == score_target) // 2 + 1\n","\treturn rank\n","\n","def metrics(rank):\n","    mrr = np.mean(1 / rank)\n","    hit10 = np.sum(rank < 11) / len(rank)\n","    hit3 = np.sum(rank < 4) / len(rank)\n","    hit1 = np.sum(rank < 2) / len(rank)\n","    return mrr, hit10, hit3, hit1"],"metadata":{"id":"YjFx5ALxnShV","executionInfo":{"status":"ok","timestamp":1747362335282,"user_tz":-540,"elapsed":7,"user":{"displayName":"URP","userId":"16515248769931109428"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# Model.py"],"metadata":{"id":"uu_H9jBNmDRJ"}},{"cell_type":"code","source":["class VTHN(nn.Module):\n","    def __init__(self, num_ent, num_rel, ent_vis, rel_vis, dim_vis, ent_txt, rel_txt, dim_txt, ent_vis_mask, rel_vis_mask,\n","                 dim_str, num_head, dim_hid, num_layer_enc_ent, num_layer_enc_rel, num_layer_prediction, num_layer_context,\n","                 dropout=0.1, emb_dropout=0.6, vis_dropout=0.1, txt_dropout=0.1, emb_as_proj=False):\n","        super(VTHN, self).__init__()\n","        self.dim_str = dim_str\n","        self.num_head = num_head\n","        self.dim_hid = dim_hid\n","        self.num_ent = num_ent\n","        self.num_rel = num_rel\n","        self.mask_token_id = num_ent + num_rel  # 마스킹 인덱스 정의\n","\n","        self.ent_vis = ent_vis\n","        self.rel_vis = rel_vis\n","        self.ent_txt = ent_txt.unsqueeze(dim=1)\n","        self.rel_txt = rel_txt.unsqueeze(dim=1)\n","\n","        false_ents = torch.full((self.num_ent, 1), False).cuda()\n","        self.ent_mask = torch.cat([false_ents, false_ents, ent_vis_mask, false_ents], dim=1)\n","        false_rels = torch.full((self.num_rel, 1), False).cuda()\n","        self.rel_mask = torch.cat([false_rels, false_rels, rel_vis_mask, false_rels], dim=1)\n","\n","        self.ent_token = nn.Parameter(torch.Tensor(1, 1, dim_str))\n","        self.rel_token = nn.Parameter(torch.Tensor(1, 1, dim_str))\n","        self.nv_token = nn.Parameter(torch.Tensor(1, 1, dim_str))\n","        self.q_rel_token = nn.Parameter(torch.Tensor(1, 1, dim_str))\n","        self.q_v_token = nn.Parameter(torch.Tensor(1, 1, dim_str))\n","\n","        self.ent_embeddings = nn.Parameter(torch.Tensor(num_ent, 1, dim_str))\n","        self.rel_embeddings = nn.Parameter(torch.Tensor(num_rel, 1, dim_str))\n","\n","        self.lp_token = nn.Parameter(torch.Tensor(1, dim_str))\n","        self.rp_token = nn.Parameter(torch.Tensor(1, dim_str))\n","        self.nvp_token = nn.Parameter(torch.Tensor(1, dim_str))\n","\n","        self.ent_dec = nn.Linear(dim_str, num_ent)\n","        self.rel_dec = nn.Linear(dim_str, num_rel)\n","        self.num_dec = nn.Linear(dim_str, num_rel)\n","\n","        self.num_mask = nn.Parameter(torch.tensor(0.5))\n","\n","        self.str_ent_ln = nn.LayerNorm(dim_str)\n","        self.str_rel_ln = nn.LayerNorm(dim_str)\n","        self.str_nv_ln = nn.LayerNorm(dim_str)\n","        self.vis_ln = nn.LayerNorm(dim_str)\n","        self.txt_ln = nn.LayerNorm(dim_str)\n","\n","        self.embdr = nn.Dropout(p=emb_dropout)\n","        self.visdr = nn.Dropout(p=vis_dropout)\n","        self.txtdr = nn.Dropout(p=txt_dropout)\n","\n","        self.pos_str_ent = nn.Parameter(torch.Tensor(1, 1, dim_str))\n","        self.pos_vis_ent = nn.Parameter(torch.Tensor(1, 1, dim_str))\n","        self.pos_txt_ent = nn.Parameter(torch.Tensor(1, 1, dim_str))\n","        self.pos_str_rel = nn.Parameter(torch.Tensor(1, 1, dim_str))\n","        self.pos_vis_rel = nn.Parameter(torch.Tensor(1, 1, dim_str))\n","        self.pos_txt_rel = nn.Parameter(torch.Tensor(1, 1, dim_str))\n","\n","        self.pos_head = nn.Parameter(torch.Tensor(1, 1, dim_str))\n","        self.pos_rel = nn.Parameter(torch.Tensor(1, 1, dim_str))\n","        self.pos_tail = nn.Parameter(torch.Tensor(1, 1, dim_str))\n","        self.pos_q = nn.Parameter(torch.Tensor(1, 1, dim_str))\n","        self.pos_v = nn.Parameter(torch.Tensor(1, 1, dim_str))\n","\n","        self.pos_triplet = nn.Parameter(torch.Tensor(1, 1, dim_str))\n","        self.pos_qualifier = nn.Parameter(torch.Tensor(1, 1, dim_str))\n","\n","        if dim_vis > 0: # numeric triplet 처리\n","            self.proj_ent_vis = nn.Linear(dim_vis, dim_str)\n","            self.proj_rel_vis = nn.Linear(3 * dim_vis, dim_str)\n","        else:\n","            self.proj_ent_vis = nn.Identity()\n","            self.proj_rel_vis = nn.Identity()\n","        self.proj_txt = nn.Linear(dim_txt, dim_str)\n","\n","        self.pri_enc = nn.Linear(self.dim_str * 3, self.dim_str)\n","        self.qv_enc = nn.Linear(self.dim_str * 2, self.dim_str)\n","\n","\n","        ent_encoder_layer = nn.TransformerEncoderLayer(dim_str, num_head, dim_hid, dropout, batch_first=True)\n","        self.ent_encoder = nn.TransformerEncoder(ent_encoder_layer, num_layer_enc_ent)\n","        rel_encoder_layer = nn.TransformerEncoderLayer(dim_str, num_head, dim_hid, dropout, batch_first=True)\n","        self.rel_encoder = nn.TransformerEncoder(rel_encoder_layer, num_layer_enc_rel)\n","        context_transformer_layer = nn.TransformerEncoderLayer(dim_str, num_head, dim_hid, dropout, batch_first=True)\n","        self.context_transformer = nn.TransformerEncoder(context_transformer_layer, num_layer_context)\n","        prediction_transformer_layer = nn.TransformerEncoderLayer(dim_str, num_head, dim_hid, dropout, batch_first=True)\n","        self.prediction_transformer = nn.TransformerEncoder(prediction_transformer_layer, num_layer_prediction)\n","\n","        nn.init.xavier_uniform_(self.ent_embeddings)\n","        nn.init.xavier_uniform_(self.rel_embeddings)\n","        nn.init.xavier_uniform_(self.proj_ent_vis.weight)\n","        nn.init.xavier_uniform_(self.proj_rel_vis.weight)\n","        nn.init.xavier_uniform_(self.proj_txt.weight)\n","\n","        nn.init.xavier_uniform_(self.ent_token)\n","        nn.init.xavier_uniform_(self.rel_token)\n","        nn.init.xavier_uniform_(self.nv_token)\n","\n","        nn.init.xavier_uniform_(self.lp_token)\n","        nn.init.xavier_uniform_(self.rp_token)\n","        nn.init.xavier_uniform_(self.nvp_token)\n","\n","        nn.init.xavier_uniform_(self.pos_str_ent)\n","        nn.init.xavier_uniform_(self.pos_vis_ent)\n","        nn.init.xavier_uniform_(self.pos_txt_ent)\n","        nn.init.xavier_uniform_(self.pos_str_rel)\n","        nn.init.xavier_uniform_(self.pos_vis_rel)\n","        nn.init.xavier_uniform_(self.pos_txt_rel)\n","        nn.init.xavier_uniform_(self.pos_head)\n","        nn.init.xavier_uniform_(self.pos_rel)\n","        nn.init.xavier_uniform_(self.pos_tail)\n","        nn.init.xavier_uniform_(self.pos_q)\n","        nn.init.xavier_uniform_(self.pos_v)\n","        nn.init.xavier_uniform_(self.pos_triplet)\n","        nn.init.xavier_uniform_(self.pos_qualifier)\n","\n","        nn.init.xavier_uniform_(self.ent_dec.weight)\n","        nn.init.xavier_uniform_(self.rel_dec.weight)\n","        nn.init.xavier_uniform_(self.num_dec.weight)\n","\n","        self.proj_ent_vis.bias.data.zero_()\n","        self.proj_rel_vis.bias.data.zero_()\n","        self.proj_txt.bias.data.zero_()\n","\n","        self.emb_as_proj = emb_as_proj\n","\n","    def forward(self, src, num_values, src_key_padding_mask, mask_locs):\n","        batch_size = len(src)\n","        num_val = torch.where(num_values != -1, num_values, self.num_mask)\n","\n","        # entity & relation embedding\n","        ent_tkn = self.ent_token.tile(self.num_ent, 1, 1)\n","        rep_ent_str = self.embdr(self.str_ent_ln(self.ent_embeddings)) + self.pos_str_ent\n","        rep_ent_vis = self.visdr(self.vis_ln(self.proj_ent_vis(self.ent_vis))) + self.pos_vis_ent\n","        rep_ent_txt = self.txtdr(self.txt_ln(self.proj_txt(self.ent_txt))) + self.pos_txt_ent\n","        ent_seq = torch.cat([ent_tkn, rep_ent_str, rep_ent_vis, rep_ent_txt], dim=1)\n","        ent_embs = self.ent_encoder(ent_seq, src_key_padding_mask=self.ent_mask)[:, 0]\n","\n","        rel_tkn = self.rel_token.tile(self.num_rel, 1, 1)\n","        rep_rel_str = self.embdr(self.str_rel_ln(self.rel_embeddings)) + self.pos_str_rel\n","        rep_rel_vis = self.visdr(self.vis_ln(self.proj_rel_vis(self.rel_vis))) + self.pos_vis_rel\n","        rep_rel_txt = self.txtdr(self.txt_ln(self.proj_txt(self.rel_txt))) + self.pos_txt_rel\n","        rel_seq = torch.cat([rel_tkn, rep_rel_str, rep_rel_vis, rep_rel_txt], dim=1)\n","        rel_embs = self.rel_encoder(rel_seq, src_key_padding_mask=self.rel_mask)[:, 0]\n","\n","        # masking된 인덱스가 범위를 벗어나지 않도록 방어 처리\n","        h_idx = src[..., 0].clamp(0, self.num_ent - 1)\n","        r_idx = src[..., 1].clamp(0, self.num_rel - 1)\n","        t_idx = src[..., 2].clamp(0, self.num_ent - 1)\n","        q_idx = src[..., 3::2].flatten().clamp(0, self.num_rel - 1)\n","        v_idx = src[..., 4::2].flatten().clamp(0, self.num_ent - 1)\n","\n","        h_seq = ent_embs[h_idx].view(batch_size, 1, self.dim_str)\n","        r_seq = rel_embs[r_idx].view(batch_size, 1, self.dim_str)\n","        t_seq = (ent_embs[t_idx] * num_val[..., 0:1]).view(batch_size, 1, self.dim_str)\n","        q_seq = rel_embs[q_idx].view(batch_size, -1, self.dim_str)\n","        v_seq = (ent_embs[v_idx] * num_val[..., 1:].flatten().unsqueeze(-1)).view(batch_size, -1, self.dim_str)\n","\n","        tri_seq = self.pri_enc(torch.cat([h_seq, r_seq, t_seq], dim=-1)) + self.pos_triplet\n","        qv_seqs = self.qv_enc(torch.cat([q_seq, v_seq], dim=-1)) + self.pos_qualifier\n","\n","        enc_in_seq = torch.cat([tri_seq, qv_seqs], dim=1)\n","        enc_out_seq = self.context_transformer(enc_in_seq, src_key_padding_mask=src_key_padding_mask)\n","\n","        dec_in_rep = enc_out_seq[mask_locs].view(batch_size, 1, self.dim_str)\n","        triplet = torch.stack([h_seq + self.pos_head, r_seq + self.pos_rel, t_seq + self.pos_tail], dim=2)\n","        qv = torch.stack([q_seq + self.pos_q, v_seq + self.pos_v, torch.zeros_like(v_seq)], dim=2)\n","        dec_in_part = torch.cat([triplet, qv], dim=1)[mask_locs]\n","\n","        dec_in_seq = torch.cat([dec_in_rep, dec_in_part], dim=1)\n","        dec_in_mask = torch.full((batch_size, 4), False, device=src.device)\n","        dec_in_mask[torch.nonzero(mask_locs == 1)[:, 1] != 0, 3] = True\n","        dec_out_seq = self.prediction_transformer(dec_in_seq, src_key_padding_mask=dec_in_mask)\n","\n","        return self.ent_dec(dec_out_seq), self.rel_dec(dec_out_seq), self.num_dec(dec_out_seq)"],"metadata":{"id":"2CgXgeAXmg-C","executionInfo":{"status":"ok","timestamp":1747362335283,"user_tz":-540,"elapsed":6,"user":{"displayName":"URP","userId":"16515248769931109428"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["# Dataset.py"],"metadata":{"id":"cQiHkCXOmfb6"}},{"cell_type":"code","execution_count":21,"metadata":{"id":"mTMmNF8Cl5it","executionInfo":{"status":"ok","timestamp":1747363895667,"user_tz":-540,"elapsed":11,"user":{"displayName":"URP","userId":"16515248769931109428"}}},"outputs":[],"source":["class VTHNKG(Dataset):\n","    def __init__(self, data, max_vis_len = -1, test = False):\n","        # entity, relation data 로드\n","        self.data = data\n","        # self.dir = \"{}\".format(self.data)\n","        self.dir = \"/content/drive/MyDrive/code/VTHNKG-OT/\" ################# Change dataset here!! ####################\n","        self.ent2id = {}\n","        self.id2ent = {}\n","        self.rel2id = {}\n","        self.id2rel = {}\n","        with open(self.dir+\"entity2id.txt\") as f:\n","            lines = f.readlines()\n","            self.num_ent = int(lines[0].strip())\n","            for line in lines[1:]:\n","                ent, idx = line.strip().split(\"\\t\")\n","                self.ent2id[ent] = int(idx)\n","                self.id2ent[int(idx)] = ent\n","\n","        with open(self.dir+\"relation2id.txt\") as f:\n","            lines = f.readlines()\n","            self.num_rel = int(lines[0].strip())\n","            for line in lines[1:]:\n","                rel, idx = line.strip().split(\"\\t\")\n","                self.rel2id[rel] = int(idx)\n","                self.id2rel[int(idx)] = rel\n","\n","        # train data 로드\n","        self.train = []\n","        self.train_pad = []\n","        self.train_num = []\n","        self.train_len = []\n","        self.max_len = 0\n","        with open(self.dir+\"train.txt\") as f:\n","            for line in f.readlines()[1:]:\n","                hp_triplet = line.strip().split(\"\\t\")\n","                h,r,t = hp_triplet[:3]\n","                num_qual = (len(hp_triplet)-3)//2\n","                self.train_len.append(len(hp_triplet))\n","                try:\n","                    self.train_num.append([float(t)])\n","                    self.train.append([self.ent2id[h],self.rel2id[r],self.num_ent+self.rel2id[r]])\n","                except:\n","                    self.train.append([self.ent2id[h],self.rel2id[r],self.ent2id[t]])\n","                    self.train_num.append([1])\n","                self.train_pad.append([False])\n","                for i in range(num_qual):\n","                    q = hp_triplet[3+2*i]\n","                    v = hp_triplet[4+2*i]\n","                    self.train[-1].append(self.rel2id[q])\n","                    try:\n","                        self.train_num[-1].append(float(v))\n","                        self.train[-1].append(self.num_ent+self.rel2id[q])\n","                    except:\n","                        self.train_num[-1].append(1)\n","                        self.train[-1].append(self.ent2id[v])\n","                    self.train_pad[-1].append(False)\n","                tri_len = num_qual*2+3\n","                if tri_len > self.max_len:\n","                    self.max_len = tri_len\n","        self.num_train = len(self.train)\n","        for i in range(self.num_train):\n","            curr_len = len(self.train[i])\n","            for j in range((self.max_len-curr_len)//2):\n","                self.train[i].append(0)\n","                self.train[i].append(0)\n","                self.train_pad[i].append(True)\n","                self.train_num[i].append(1)\n","\n","        # test data 로드\n","        self.test = []\n","        self.test_pad = []\n","        self.test_num = []\n","        self.test_len = []\n","        if test:\n","            test_dir = self.dir + \"test.txt\"\n","        else:\n","            test_dir = self.dir + \"valid.txt\"\n","        with open(test_dir) as f:\n","            for line in f.readlines()[1:]:\n","                hp_triplet = []\n","                hp_pad = []\n","                hp_num = []\n","                for i, anything in enumerate(line.strip().split(\"\\t\")):\n","                    if i % 2 == 0 and i != 0:\n","                        try:\n","                            hp_num.append(float(anything))\n","                            hp_triplet.append(self.num_ent + hp_triplet[-1])\n","                        except:\n","                            hp_triplet.append(self.ent2id[anything])\n","                            hp_num.append(1)\n","                    elif i == 0:\n","                        hp_triplet.append(self.ent2id[anything])\n","                    else:\n","                        hp_triplet.append(self.rel2id[anything])\n","                        hp_pad.append(False)\n","                flag = 0\n","                self.test_len.append(len(hp_triplet))\n","                while len(hp_triplet) < self.max_len:\n","                    hp_triplet.append(0)\n","                    flag += 1\n","                    if flag % 2:\n","                        hp_num.append(1)\n","                        hp_pad.append(True)\n","                self.test.append(hp_triplet)\n","                self.test_pad.append(hp_pad)\n","                self.test_num.append(hp_num)\n","        self.num_test = len(self.test)\n","\n","        # validation data 로드\n","        self.valid = []\n","        self.valid_pad = []\n","        self.valid_num = []\n","        self.valid_len = []\n","        if test:\n","            valid_dir = self.dir + \"valid.txt\"\n","        else:\n","            valid_dir = self.dir + \"test.txt\"\n","        with open(valid_dir) as f:\n","            for line in f.readlines()[1:]:\n","                hp_triplet = []\n","                hp_pad = []\n","                hp_num = []\n","                for i, anything in enumerate(line.strip().split(\"\\t\")):\n","                    if i % 2 == 0 and i != 0:\n","                        try:\n","                            hp_num.append(float(anything))\n","                            hp_triplet.append(self.num_ent + hp_triplet[-1])\n","                        except:\n","                            hp_triplet.append(self.ent2id[anything])\n","                            hp_num.append(1)\n","                    elif i == 0:\n","                        hp_triplet.append(self.ent2id[anything])\n","                    else:\n","                        hp_triplet.append(self.rel2id[anything])\n","                        hp_pad.append(False)\n","                flag = 0\n","                self.valid_len.append(len(hp_triplet))\n","                while len(hp_triplet) < self.max_len:\n","                    hp_triplet.append(0)\n","                    flag += 1\n","                    if flag % 2:\n","                        hp_num.append(1)\n","                        hp_pad.append(True)\n","                self.valid.append(hp_triplet)\n","                self.valid_pad.append(hp_pad)\n","                self.valid_num.append(hp_num)\n","        self.num_valid = len(self.valid)\n","\n","        # 예측을 위한 filter dictionary 생성\n","        self.filter_dict = self.construct_filter_dict()\n","        self.train = torch.tensor(self.train)\n","        self.train_pad = torch.tensor(self.train_pad)\n","        self.train_num = torch.tensor(self.train_num)\n","        self.train_len = torch.tensor(self.train_len)\n","\n","        # Visual Textual data 로드\n","        self.max_vis_len_ent = max_vis_len\n","        self.max_vis_len_rel = max_vis_len\n","        self.gather_vis_feature()\n","        self.gather_txt_feature()\n","\n","    # VISTA dataset.py 인용\n","    def sort_vis_features(self, item = 'entity'):\n","        if item == 'entity':\n","            vis_feats = torch.load(self.dir + 'visual_features_ent.pt')\n","        elif item == 'relation':\n","            vis_feats = torch.load(self.dir + 'visual_features_rel.pt')\n","        else:\n","            raise NotImplementedError\n","\n","        sorted_vis_feats = {}\n","        for obj in tqdm(vis_feats):\n","            if item == 'entity' and obj not in self.ent2id:\n","                continue\n","            if item == 'relation' and obj not in self.rel2id:\n","                continue\n","            num_feats = len(vis_feats[obj])\n","            sim_val = torch.zeros(num_feats).cuda()\n","            iterate = tqdm(range(num_feats)) if num_feats > 1000 else range(num_feats)\n","            cudaed_feats = vis_feats[obj].cuda()\n","            for i in iterate:\n","                sims = torch.inner(cudaed_feats[i], cudaed_feats[i:])\n","                sim_val[i:] += sims\n","                sim_val[i] += sims.sum()-torch.inner(cudaed_feats[i], cudaed_feats[i])\n","            sorted_vis_feats[obj] = vis_feats[obj][torch.argsort(sim_val, descending = True)]\n","\n","        if item == 'entity':\n","            torch.save(sorted_vis_feats, self.dir+ \"visual_features_ent_sorted.pt\")\n","        else:\n","            torch.save(sorted_vis_feats, self.dir+ \"visual_features_rel_sorted.pt\")\n","\n","        return sorted_vis_feats\n","\n","    # VISTA dataset.py 인용\n","    def gather_vis_feature(self):\n","        if os.path.isfile(self.dir + 'visual_features_ent_sorted.pt'):\n","            # self.logger.info(\"Found sorted entity visual features!\")\n","            self.ent2vis = torch.load(self.dir + 'visual_features_ent_sorted.pt')\n","        elif os.path.isfile(self.dir + 'visual_features_ent.pt'):\n","            # self.logger.info(\"Entity visual features are not sorted! sorting...\")\n","            self.ent2vis = self.sort_vis_features(item = 'entity')\n","        else:\n","            # self.logger.info(\"Entity visual features are not found!\")\n","            self.ent2vis = {}\n","\n","        if os.path.isfile(self.dir + 'visual_features_rel_sorted.pt'):\n","            # self.logger.info(\"Found sorted relation visual features!\")\n","            self.rel2vis = torch.load(self.dir + 'visual_features_rel_sorted.pt')\n","        elif os.path.isfile(self.dir + 'visual_features_rel.pt'):\n","            # self.logger.info(\"Relation visual feature are not sorted! sorting...\")\n","            self.rel2vis = self.sort_vis_features(item = 'relation')\n","        else:\n","            # self.logger.info(\"Relation visual features are not found!\")\n","            self.rel2vis = {}\n","\n","        self.vis_feat_size = len(self.ent2vis[list(self.ent2vis.keys())[0]][0])\n","\n","        total_num = 0\n","        if self.max_vis_len_ent != -1:\n","            for ent_name in self.ent2vis:\n","                num_feats = len(self.ent2vis[ent_name])\n","                total_num += num_feats\n","                self.ent2vis[ent_name] = self.ent2vis[ent_name][:self.max_vis_len_ent]\n","            for rel_name in self.rel2vis:\n","                self.rel2vis[rel_name] = self.rel2vis[rel_name][:self.max_vis_len_rel]\n","        else:\n","            for ent_name in self.ent2vis:\n","                num_feats = len(self.ent2vis[ent_name])\n","                total_num += num_feats\n","                if self.max_vis_len_ent < len(self.ent2vis[ent_name]):\n","                    self.max_vis_len_ent = len(self.ent2vis[ent_name])\n","            self.max_vis_len_ent = max(self.max_vis_len_ent, 0)\n","            for rel_name in self.rel2vis:\n","                if self.max_vis_len_rel < len(self.rel2vis[rel_name]):\n","                    self.max_vis_len_rel = len(self.rel2vis[rel_name])\n","            self.max_vis_len_rel = max(self.max_vis_len_rel, 0)\n","        self.ent_vis_mask = torch.full((self.num_ent, self.max_vis_len_ent), True).cuda()\n","        self.ent_vis_matrix = torch.zeros((self.num_ent, self.max_vis_len_ent, self.vis_feat_size)).cuda()\n","        self.rel_vis_mask = torch.full((self.num_rel, self.max_vis_len_rel), True).cuda()\n","        self.rel_vis_matrix = torch.zeros((self.num_rel, self.max_vis_len_rel, 3*self.vis_feat_size)).cuda()\n","\n","\n","        for ent_name in self.ent2vis:\n","            ent_id = self.ent2id[ent_name]\n","            num_feats = len(self.ent2vis[ent_name])\n","            self.ent_vis_mask[ent_id, :num_feats] = False\n","            self.ent_vis_matrix[ent_id, :num_feats] = self.ent2vis[ent_name]\n","\n","        for rel_name in self.rel2vis:\n","            rel_id = self.rel2id[rel_name]\n","            num_feats = len(self.rel2vis[rel_name])\n","            self.rel_vis_mask[rel_id, :num_feats] = False\n","            self.rel_vis_matrix[rel_id, :num_feats] = self.rel2vis[rel_name]\n","\n","    # VISTA dataset.py 인용\n","    def gather_txt_feature(self):\n","\n","        self.ent2txt = torch.load(self.dir + 'textual_features_ent.pt')\n","        self.rel2txt = torch.load(self.dir + 'textual_features_rel.pt')\n","        self.txt_feat_size = len(self.ent2txt[self.id2ent[0]])\n","\n","        self.ent_txt_matrix = torch.zeros((self.num_ent, self.txt_feat_size)).cuda()\n","        self.rel_txt_matrix = torch.zeros((self.num_rel, self.txt_feat_size)).cuda()\n","\n","        for ent_name in self.ent2id:\n","            self.ent_txt_matrix[self.ent2id[ent_name]] = self.ent2txt[ent_name]\n","\n","        for rel_name in self.rel2id:\n","            self.rel_txt_matrix[self.rel2id[rel_name]] = self.rel2txt[rel_name]\n","\n","\n","    def __len__(self):\n","        return self.num_train\n","\n","    def __getitem__(self, idx):\n","        masked = self.train[idx].clone()\n","        masked_num = self.train_num[idx].clone()\n","        mask_idx = np.random.randint(self.train_len[idx])\n","\n","        if mask_idx % 2 == 0:\n","            if self.train[idx, mask_idx] < self.num_ent:\n","                masked[mask_idx] = self.num_ent+self.num_rel\n","        else:\n","            masked[mask_idx] = self.num_rel\n","            if masked[mask_idx+1] >= self.num_ent:\n","                masked[mask_idx+1] = self.num_ent+self.num_rel\n","        answer = self.train[idx, mask_idx]\n","\n","        mask_locs = torch.full(((self.max_len-3)//2+1,), False)\n","        if mask_idx < 3:\n","            mask_locs[0] = True\n","        else:\n","            mask_locs[(mask_idx-3)//2+1] = True\n","\n","        mask_idx_mask = torch.full((4,), False)\n","        if mask_idx < 3:\n","            mask_idx_mask[mask_idx+1] = True\n","        else:\n","            mask_idx_mask[2-mask_idx%2] = True\n","\n","        num_idx_mask = torch.full((self.num_rel,),False)\n","        if mask_idx % 2 == 0:\n","            if self.train[idx, mask_idx] >= self.num_ent:\n","                num_idx_mask[self.train[idx,mask_idx]-self.num_ent] = True\n","                answer = self.train_num[idx, (mask_idx-1)//2]\n","                masked_num[mask_idx//2-1] = -1\n","                ent_mask = [0]\n","                num_mask = [1]\n","            else:\n","                num_mask = [0]\n","                ent_mask = [1]\n","            rel_mask = [0]\n","        else:\n","            num_mask = [0]\n","            ent_mask = [0]\n","            rel_mask = [1]\n","\n","        return masked, self.train_pad[idx], mask_locs, answer, mask_idx_mask, masked_num, torch.tensor(ent_mask), torch.tensor(rel_mask), torch.tensor(num_mask), num_idx_mask, self.train_len[idx]\n","\n","    def max_len(self):\n","        return self.max_len\n","\n","    def construct_filter_dict(self):\n","        res = {}\n","        for data, data_len, data_num in [[self.train, self.train_len, self.train_num],[self.valid, self.valid_len, self.valid_num],[self.test, self.test_len, self.test_num]]:\n","            for triplet, triplet_len, triplet_num in zip(data, data_len, data_num):\n","                real_triplet = copy.deepcopy(triplet[:triplet_len])\n","                if real_triplet[2] < self.num_ent:\n","                    re_pair = [(real_triplet[0], real_triplet[1], real_triplet[2])]\n","                else:\n","                    re_pair = [(real_triplet[0], real_triplet[1], real_triplet[1]*2 + triplet_num[0])]\n","                for idx, (q,v) in enumerate(zip(real_triplet[3::2], real_triplet[4::2])):\n","                    if v <self.num_ent:\n","                        re_pair.append((q, v))\n","                    else:\n","                        re_pair.append((q, q*2 + triplet_num[idx + 1]))\n","                for i, pair in enumerate(re_pair):\n","                    for j, anything in enumerate(pair):\n","                        filtered_filter = copy.deepcopy(re_pair)\n","                        new_pair = copy.deepcopy(list(pair))\n","                        new_pair[j] = 2*(self.num_ent+self.num_rel)\n","                        filtered_filter[i] = tuple(new_pair)\n","                        filtered_filter.sort()\n","                        try:\n","                            res[tuple(filtered_filter)].append(pair[j])\n","                        except:\n","                            res[tuple(filtered_filter)] = [pair[j]]\n","        for key in res:\n","            res[key] = np.array(res[key])\n","\n","        return res"]},{"cell_type":"markdown","source":["# Train.py"],"metadata":{"id":"jAAtyrlFmKaq"}},{"cell_type":"markdown","source":[],"metadata":{"id":"fRYvXkTNmgw0"}},{"cell_type":"code","source":["%cd \"/content/drive/MyDrive/code/VTHNKG-OT/\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I3PfJz9pIhed","executionInfo":{"status":"ok","timestamp":1747363897616,"user_tz":-540,"elapsed":14,"user":{"displayName":"URP","userId":"16515248769931109428"}},"outputId":"c0262800-a9f3-46ec-835b-613f928b6d17"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/code/VTHNKG-OT\n"]}]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rRs6lIep7NHR","executionInfo":{"status":"ok","timestamp":1747363899112,"user_tz":-540,"elapsed":104,"user":{"displayName":"URP","userId":"16515248769931109428"}},"outputId":"f6aaf419-455c-48fb-e306-c6e6d8227543"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":[" checkpoint\t\t     relations.txt\n"," entities.txt\t\t     result\n"," entity2id.txt\t\t     test.txt\n"," entity2textlong.txt\t     textual_features_ent.pt\n"," entity2text.txt\t     textual_features_rel.pt\n","'Model based on VTHNKG-OT'   train.txt\n","'process VTHNKG-OT'\t     triplets.txt\n"," relation2id.txt\t     valid.txt\n"," relation2textlong.txt\t     visual_features_ent_sorted.pt\n"," relation2text.txt\t     visual_features_rel_sorted.pt\n"]}]},{"cell_type":"code","source":["# import 및 초기 세팅 (코어, 랜덤 시드, logger)\n","\n","# HyNT와 동일\n","OMP_NUM_THREADS=8\n","torch.backends.cudnn.benchmark = True\n","torch.set_num_threads(8)\n","torch.cuda.empty_cache()\n","\n","torch.manual_seed(0)\n","random.seed(0)\n","np.random.seed(0)\n","\n","# argument 정의\n","\"\"\"\n","data 종류\n","learning rate\n","dimension of embedding\n","number of epoch\n","validation period (epoch)\n","number of layer for entity encoder\n","number of layer for relation encoder\n","number of layer for context encoder\n","number of layer for prediction decoder\n","head number\n","hidden dimension for feedforward\n","dropout rate\n","smoothing rate\n","batch size\n","step size\n","\"\"\"\n","\n","parser = argparse.ArgumentParser()\n","parser.add_argument('--exp', default='Reproduce') # 실험 이름\n","parser.add_argument('--data', default = \"VTHNKG-OT\", type = str)\n","parser.add_argument('--lr', default=4e-4, type=float)\n","parser.add_argument('--dim', default=256, type=int)\n","parser.add_argument('--num_epoch', default=1050, type=int)        # Tuning 필요\n","parser.add_argument('--valid_epoch', default=150, type=int)\n","parser.add_argument('--num_layer_enc_ent', default=4, type=int)   # Tuning 필요\n","parser.add_argument('--num_layer_enc_rel', default=4, type=int)   # Tuning 필요\n","#parser.add_argument('--num_layer_enc_nv', default=4, type=int)  < numeric value는 visual-textual feagture이 없으므로 transformer로 학습할 필요 X\n","parser.add_argument('--num_layer_prediction', default=4, type=int)   # Tuning 필요\n","parser.add_argument('--num_layer_context', default=4, type=int)  # Tuning 필요\n","parser.add_argument('--num_head', default=8, type=int)            # Tuning 필요?\n","parser.add_argument('--hidden_dim', default = 2048, type = int)   # Tuning 필요?\n","parser.add_argument('--dropout', default = 0.15, type = float)    # Tuning 필요\n","parser.add_argument('--emb_dropout', default = 0.15, type = float)    # Tuning 필요\n","parser.add_argument('--vis_dropout', default = 0.15, type = float)    # Tuning 필요\n","parser.add_argument('--txt_dropout', default = 0.15, type = float)    # Tuning 필요\n","parser.add_argument('--smoothing', default = 0.4, type = float)   # Tuning 필요\n","parser.add_argument('--max_img_num', default = 3, type = int)\n","parser.add_argument('--batch_size', default = 1024, type = int)\n","parser.add_argument('--step_size', default = 150, type = int)     # Tuning 필요?\n","# exp, no_Write, emb_as_proj는 단순화 제외되었음.\n","args, unknown = parser.parse_known_args()"],"metadata":{"id":"HmgS2m1upzp1","executionInfo":{"status":"ok","timestamp":1747363900376,"user_tz":-540,"elapsed":3,"user":{"displayName":"URP","userId":"16515248769931109428"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["# 모델 불러오기 및 데이터 로딩 (model.py 와 dataset.py)\n","KG = VTHNKG(args.data, max_vis_len = args.max_img_num, test = False)\n","\n","KG_DataLoader = torch.utils.data.DataLoader(KG, batch_size = args.batch_size ,shuffle = True)\n","\"\"\"\n","num_ent\n","num_rel\n","num_nv\n","num_qual\n","ent_vis\n","rel_vis\n","dim_vis\n","ent_txt\n","rel_txt\n","dim_txt\n","ent_vis_mask\n","rel_vis_mask\n","dim_str\n","num_head\n","dim_hid\n","num_layer_enc_ent\n","num_layer_enc_rel\n","num_layer_prediction\n","num_layer_context\n","dropout = 0.1\n","emb_dropout = 0.6\n","vis_dropout = 0.1\n","txt_dropout = 0.1\n","max_qual = 5\n","emb_as_proj = False\n","\"\"\"\n","model = VTHN(\n","    num_ent = KG.num_ent, # 엔티티 개수\n","    num_rel = KG.num_rel, # relation 개수\n","    ## num_nv = KG.num_nv, # numeric value 개수 -> 필요 없음\n","    ## num_qual = KG.num_qual, # qualifier 개수 -> 필요 없음\n","    ent_vis = KG.ent_vis_matrix, # entity에 대한 visual feature\n","    rel_vis = KG.rel_vis_matrix, # relation에 대한 visual feature\n","    dim_vis = KG.vis_feat_size, # visual feature의 dimension\n","    ent_txt = KG.ent_txt_matrix, # entity의 textual feature\n","    rel_txt = KG.rel_txt_matrix, # relation의 textual feature\n","    dim_txt = KG.txt_feat_size, # textual feature의 dimension\n","    ent_vis_mask = KG.ent_vis_mask, # entity의 visual feature의 유무 판정 마스크\n","    rel_vis_mask = KG.rel_vis_mask, # relation의 visual feature의 유무 판정 마스크\n","    dim_str = args.dim, # structual dimension(기본이 되는 차원)\n","    num_head = args.num_head, # multihead 개수\n","    dim_hid = args.hidden_dim, # ff layer hidden layer dimension\n","    num_layer_enc_ent = args.num_layer_enc_ent, # entity encoder layer 개수\n","    num_layer_enc_rel = args.num_layer_enc_rel, # relation encoder layer 개수\n","    num_layer_prediction = args.num_layer_prediction, # prediction transformer layer 개수\n","    num_layer_context = args.num_layer_context, # context transformer layer 개수\n","    dropout = args.dropout, # transformer layer의 dropout\n","    emb_dropout = args.emb_dropout, # structural embedding 생성에서의 dropout (structural 정보를 얼마나 버릴지 결정)\n","    vis_dropout = args.vis_dropout, # visual embedding 생성에서의 dropout (visual 정보를 얼마나 버릴지 결정)\n","    txt_dropout = args.txt_dropout, # textual embedding 생성에서의 dropout (textual 정보를 얼마나 버릴지 결정)\n","    ## max_qual = 5, # qualfier 최대 개수 (padding 때문에 필요) -> 이후의 batch_pad 계산 방식으로 인해 필요 없음.\n","    emb_as_proj = False # 학습 효율성을 위한 조정\n",")\n","\n","model = model.cuda()\n","\n","# loss function, optimizer, scheduler, logging, savepoint 정의\n","criterion = nn.CrossEntropyLoss(label_smoothing = args.smoothing)\n","mse_criterion = nn.MSELoss()\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n","\n","scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, args.step_size, T_mult = 2)\n","\n","file_format = f\"{args.exp}/{args.data}/lr_{args.lr}_dim_{args.dim}_\"\n","\n","\"\"\" 이 부분은 나중에 수정 필요\n","if args.emb_as_proj:\n","    file_format += \"_embproj\"\n","\"\"\"\n","os.makedirs(f\"./result/{args.exp}/{args.data}/\", exist_ok=True)\n","os.makedirs(f\"./checkpoint/{args.exp}/{args.data}/\", exist_ok=True)\n","with open(f\"./result/{file_format}.txt\", \"w\") as f:\n","    f.write(f\"{datetime.datetime.now()}\\n\")\n","\n","\n","# 학습 시작\n","\n","# epoch 반복\n","## batch마다 연산 (dataset.py에서 batch 등의 parameter 불러오는 방식 확인 필요)\n","### batch 처리 후 entity, relation, number score 계산\n","### 정답 비교 후 loss 계산\n","### loss 기반으로 backward pass, 학습\n","\n","## 특정 epoch마다 validation\n","### 모든 엔티티 (discrete, numeric)에 대해 score 및 rank 계산\n","### 모든 관계에 대해 score 및 rank 계산\n","## validation logging\n","\n","start = time.time() # 스탑워치 시작\n","print(\"EPOCH \\t TOTAL LOSS \\t ENTITY LOSS \\t RELATION LOSS \\t NUMERIC LOSS \\t TOTAL TIME\")\n","for epoch in range(args.num_epoch):\n","  total_loss = 0.0\n","  total_ent_loss = 0.0\n","  total_rel_loss = 0.0\n","  total_num_loss = 0.0\n","  for batch, batch_pad, batch_mask_locs, answers, mask_idx, batch_num, ent_mask, rel_mask, num_mask, num_idx_mask, batch_real_len in KG_DataLoader:\n","    batch_len = max(batch_real_len)\n","    batch = batch[:,:batch_len]\n","    batch_pad = batch_pad[:,:batch_len//2] ## 이렇게 할거면 max_qual이 필요 없음.\n","    batch_mask_locs = batch_mask_locs[:,:batch_len//2]\n","    batch_num = batch_num[:,:batch_len//2]\n","\n","    # 예측\n","    ent_score, rel_score, num_score = model(batch.cuda(), batch_num.cuda(), batch_pad.cuda(), batch_mask_locs.cuda())\n","    real_ent_mask = (ent_mask.cuda()!=0).squeeze()\n","    real_rel_mask = (rel_mask.cuda()!=0).squeeze()\n","    real_num_mask = (num_mask.cuda()!=0).squeeze()\n","    answer = answers.cuda()\n","    mask_idx = mask_idx.cuda()\n","\n","    # loss 계산\n","    loss = 0\n","    if torch.any(ent_mask):\n","        real_ent_mask = real_ent_mask.cuda()\n","        ent_loss = criterion(ent_score[mask_idx][real_ent_mask], answer[real_ent_mask].long())\n","        loss += ent_loss\n","        total_ent_loss += ent_loss.item()\n","\n","    if torch.any(rel_mask):\n","        real_rel_mask = real_rel_mask.cuda()\n","        rel_loss = criterion(rel_score[mask_idx][real_rel_mask], answer[real_rel_mask].long())\n","        loss += rel_loss\n","        total_rel_loss += rel_loss.item()\n","\n","    if torch.any(num_mask):\n","        real_num_mask = real_num_mask.cuda()\n","        num_loss = mse_criterion(num_score[mask_idx][num_idx_mask], answer[real_num_mask])\n","        loss += num_loss\n","        total_num_loss += num_loss.item()\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n","    optimizer.step()\n","    total_loss += loss.item()\n","\n","  scheduler.step()\n","  print(f\"{epoch} \\t {total_loss:.6f} \\t {total_ent_loss:.6f} \\t\" + \\\n","        f\"{total_rel_loss:.6f} \\t {total_num_loss:.6f} \\t {time.time() - start:.6f} s\")\n","\n","  # validation 진행\n","  if (epoch + 1) % args.valid_epoch == 0:\n","    model.eval()\n","\n","    lp_tri_list_rank = []  # 기본 triplet 링크 예측 순위 저장\n","    lp_all_list_rank = []  # 모든 링크 예측(기본+확장) 순위 저장\n","    rp_tri_list_rank = []  # 기본 triplet 관계 예측 순위 저장\n","    rp_all_list_rank = []  # 모든 관계 예측 순위 저장\n","    nvp_tri_se = 0         # 기본 triplet 숫자값 예측 제곱 오차 합\n","    nvp_tri_se_num = 0     # 기본 triplet 숫자값 예측 횟수\n","    nvp_all_se = 0         # 모든 숫자값 예측 제곱 오차 합\n","    nvp_all_se_num = 0     # 모든 숫자값 예측 횟수\n","    with torch.no_grad():\n","        for tri, tri_pad, tri_num in tqdm(zip(KG.test, KG.test_pad, KG.test_num), total = len(KG.test)):\n","            tri_len = len(tri)\n","            pad_idx = 0\n","            for ent_idx in range((tri_len+1)//2): # 총 엔티티 개수만큼큼\n","                # 패딩 확인\n","                if tri_pad[pad_idx]:\n","                    break\n","                if ent_idx != 0:\n","                    pad_idx += 1\n","\n","                # 테스트 트리플렛\n","                test_triplet = torch.tensor([tri])\n","\n","                # 마스킹 위치 설정\n","                mask_locs = torch.full((1,(KG.max_len-3)//2+1), False)\n","                if ent_idx < 2:\n","                    mask_locs[0,0] = True\n","                else:\n","                    mask_locs[0,ent_idx-1] = True\n","                if tri[ent_idx*2] >= KG.num_ent: # 숫자 예측 경우\n","                    assert ent_idx != 0\n","                    test_num = torch.tensor([tri_num])\n","                    test_num[0,ent_idx-1] = -1\n","                    # 숫자 마스킹 후 예측\n","                    _,_,score_num = model(test_triplet.cuda(), test_num.cuda(), torch.tensor([tri_pad]).cuda(), mask_locs)\n","                    score_num = score_num.detach().cpu().numpy()\n","                    if ent_idx == 1: # triplet의 숫자\n","                        sq_error = (score_num[0,3,tri[ent_idx*2]-KG.num_ent] - tri_num[ent_idx-1])**2\n","                        nvp_tri_se += sq_error\n","                        nvp_tri_se_num += 1\n","                    else: # qualifier\n","                        sq_error = (score_num[0,2,tri[ent_idx*2]-KG.num_ent] - tri_num[ent_idx-1])**2\n","                    nvp_all_se += sq_error\n","                    nvp_all_se_num += 1\n","                else: # 엔티티 예측\n","                    test_triplet[0,2*ent_idx] = KG.num_ent+KG.num_rel # 사용되는 특수 마스크 토큰 (다른 엔티티와 겹치지 않음)\n","                    filt_tri = copy.deepcopy(tri)\n","                    filt_tri[ent_idx*2] = 2*(KG.num_ent+KG.num_rel)\n","                    if ent_idx != 1 and filt_tri[2] >= KG.num_ent:\n","                        re_pair = [(filt_tri[0], filt_tri[1], filt_tri[1] * 2 + tri_num[0])] # 숫자자\n","                    else:\n","                        re_pair = [(filt_tri[0], filt_tri[1], filt_tri[2])]\n","                    for qual_idx,(q,v) in enumerate(zip(filt_tri[3::2], filt_tri[4::2])): # qualifier에 대해 반복복\n","                        if tri_pad[qual_idx+1]:\n","                            break\n","                        if ent_idx != qual_idx + 2 and v >= KG.num_ent:\n","                            re_pair.append((q, q*2 + tri_num[qual_idx + 1]))\n","                        else:\n","                            re_pair.append((q,v))\n","                    re_pair.sort()\n","                    filt = KG.filter_dict[tuple(re_pair)]\n","                    score_ent, _, _ = model(test_triplet.cuda(), torch.tensor([tri_num]).cuda(), torch.tensor([tri_pad]).cuda(), mask_locs)\n","                    score_ent = score_ent.detach().cpu().numpy()\n","                    if ent_idx < 2:\n","                        rank = calculate_rank(score_ent[0,1+2*ent_idx],tri[ent_idx*2], filt)\n","                        lp_tri_list_rank.append(rank)\n","                    else:\n","                        rank = calculate_rank(score_ent[0,2], tri[ent_idx*2], filt)\n","                    lp_all_list_rank.append(rank)\n","            for rel_idx in range(tri_len//2): # 관계에 대한 예측\n","                if tri_pad[rel_idx]:\n","                    break\n","                mask_locs = torch.full((1,(KG.max_len-3)//2+1), False)\n","                mask_locs[0,rel_idx] = True\n","                test_triplet = torch.tensor([tri])\n","                orig_rels = tri[1::2]\n","                test_triplet[0, rel_idx*2 + 1] = KG.num_rel\n","                if test_triplet[0, rel_idx*2+2] >= KG.num_ent: # 숫자값의 경우 특수 마스크 토큰큰\n","                    test_triplet[0, rel_idx*2 + 2] = KG.num_ent + KG.num_rel\n","                filt_tri = copy.deepcopy(tri)\n","                # 필터링 및 scoring (entity와 동일)\n","                filt_tri[rel_idx*2+1] = 2*(KG.num_ent+KG.num_rel)\n","                if filt_tri[2] >= KG.num_ent:\n","                    re_pair = [(filt_tri[0], filt_tri[1], orig_rels[0]*2 + tri_num[0])]\n","                else:\n","                    re_pair = [(filt_tri[0], filt_tri[1], filt_tri[2])]\n","                for qual_idx,(q,v) in enumerate(zip(filt_tri[3::2], filt_tri[4::2])):\n","                    if tri_pad[qual_idx+1]:\n","                        break\n","                    if v >= KG.num_ent:\n","                        re_pair.append((q, orig_rels[qual_idx + 1]*2 + tri_num[qual_idx + 1]))\n","                    else:\n","                        re_pair.append((q,v))\n","                re_pair.sort()\n","                filt = KG.filter_dict[tuple(re_pair)]\n","                _,score_rel, _ = model(test_triplet.cuda(), torch.tensor([tri_num]).cuda(), torch.tensor([tri_pad]).cuda(), mask_locs)\n","                score_rel = score_rel.detach().cpu().numpy()\n","                if rel_idx == 0:\n","                    rank = calculate_rank(score_rel[0,2], tri[rel_idx*2+1], filt)\n","                    rp_tri_list_rank.append(rank)\n","                else:\n","                    rank = calculate_rank(score_rel[0,1], tri[rel_idx*2+1], filt)\n","                rp_all_list_rank.append(rank)\n","\n","    lp_tri_list_rank = np.array(lp_tri_list_rank)\n","    lp_tri_mrr, lp_tri_hit10, lp_tri_hit3, lp_tri_hit1 = metrics(lp_tri_list_rank)\n","    print(\"Link Prediction on Validation Set (Tri)\")\n","    print(f\"MRR: {lp_tri_mrr:.4f}\")\n","    print(f\"Hit@10: {lp_tri_hit10:.4f}\")\n","    print(f\"Hit@3: {lp_tri_hit3:.4f}\")\n","    print(f\"Hit@1: {lp_tri_hit1:.4f}\")\n","\n","    lp_all_list_rank = np.array(lp_all_list_rank)\n","    lp_all_mrr, lp_all_hit10, lp_all_hit3, lp_all_hit1 = metrics(lp_all_list_rank)\n","    print(\"Link Prediction on Validation Set (All)\")\n","    print(f\"MRR: {lp_all_mrr:.4f}\")\n","    print(f\"Hit@10: {lp_all_hit10:.4f}\")\n","    print(f\"Hit@3: {lp_all_hit3:.4f}\")\n","    print(f\"Hit@1: {lp_all_hit1:.4f}\")\n","\n","    rp_tri_list_rank = np.array(rp_tri_list_rank)\n","    rp_tri_mrr, rp_tri_hit10, rp_tri_hit3, rp_tri_hit1 = metrics(rp_tri_list_rank)\n","    print(\"Relation Prediction on Validation Set (Tri)\")\n","    print(f\"MRR: {rp_tri_mrr:.4f}\")\n","    print(f\"Hit@10: {rp_tri_hit10:.4f}\")\n","    print(f\"Hit@3: {rp_tri_hit3:.4f}\")\n","    print(f\"Hit@1: {rp_tri_hit1:.4f}\")\n","\n","    rp_all_list_rank = np.array(rp_all_list_rank)\n","    rp_all_mrr, rp_all_hit10, rp_all_hit3, rp_all_hit1 = metrics(rp_all_list_rank)\n","    print(\"Relation Prediction on Validation Set (All)\")\n","    print(f\"MRR: {rp_all_mrr:.4f}\")\n","    print(f\"Hit@10: {rp_all_hit10:.4f}\")\n","    print(f\"Hit@3: {rp_all_hit3:.4f}\")\n","    print(f\"Hit@1: {rp_all_hit1:.4f}\")\n","\n","    if nvp_tri_se_num > 0:\n","        nvp_tri_rmse = math.sqrt(nvp_tri_se/nvp_tri_se_num)\n","        print(\"Numeric Value Prediction on Validation Set (Tri)\")\n","        print(f\"RMSE: {nvp_tri_rmse:.4f}\")\n","\n","    if nvp_all_se_num > 0:\n","        nvp_all_rmse = math.sqrt(nvp_all_se/nvp_all_se_num)\n","        print(\"Numeric Value Prediction on Validation Set (All)\")\n","        print(f\"RMSE: {nvp_all_rmse:.4f}\")\n","\n","\n","    with open(f\"./result/{file_format}.txt\", 'a') as f:\n","        f.write(f\"Epoch: {epoch+1}\\n\")\n","        f.write(f\"Link Prediction on Validation Set (Tri): {lp_tri_mrr:.4f} {lp_tri_hit10:.4f} {lp_tri_hit3:.4f} {lp_tri_hit1:.4f}\\n\")\n","        f.write(f\"Link Prediction on Validation Set (All): {lp_all_mrr:.4f} {lp_all_hit10:.4f} {lp_all_hit3:.4f} {lp_all_hit1:.4f}\\n\")\n","        f.write(f\"Relation Prediction on Validation Set (Tri): {rp_tri_mrr:.4f} {rp_tri_hit10:.4f} {rp_tri_hit3:.4f} {rp_tri_hit1:.4f}\\n\")\n","        f.write(f\"Relation Prediction on Validation Set (All): {rp_all_mrr:.4f} {rp_all_hit10:.4f} {rp_all_hit3:.4f} {rp_all_hit1:.4f}\\n\")\n","        if nvp_tri_se_num > 0:\n","            f.write(f\"Numeric Value Prediction on Validation Set (Tri): {nvp_tri_rmse:.4f}\\n\")\n","        if nvp_all_se_num > 0:\n","            f.write(f\"Numeric Value Prediction on Validation Set (All): {nvp_all_rmse:.4f}\\n\")\n","\n","\n","    torch.save({'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict()},\n","                f\"./checkpoint/{file_format}_{epoch+1}.ckpt\")\n","\n","    model.train()"],"metadata":{"id":"1bX-xxnbmPYo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747364608363,"user_tz":-540,"elapsed":706258,"user":{"displayName":"URP","userId":"16515248769931109428"}},"outputId":"0f74c656-3800-4e0c-e00c-729ed1d28692"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["EPOCH \t TOTAL LOSS \t ENTITY LOSS \t RELATION LOSS \t NUMERIC LOSS \t TOTAL TIME\n","0 \t 61.207354 \t 11.126059 \t11.520560 \t 38.560734 \t 0.776253 s\n","1 \t 28.592420 \t 10.308061 \t11.172669 \t 7.111690 \t 1.283618 s\n","2 \t 21.992743 \t 10.129913 \t10.954273 \t 0.908557 \t 1.807229 s\n","3 \t 21.082597 \t 9.834271 \t10.514894 \t 0.733431 \t 2.324631 s\n","4 \t 20.798527 \t 9.695004 \t10.246528 \t 0.856995 \t 2.859483 s\n","5 \t 20.268963 \t 9.736359 \t9.886633 \t 0.645971 \t 3.361834 s\n","6 \t 20.034911 \t 9.438468 \t10.038626 \t 0.557817 \t 3.890149 s\n","7 \t 20.189954 \t 9.420925 \t10.089323 \t 0.679706 \t 4.393708 s\n","8 \t 19.629610 \t 9.358135 \t9.736473 \t 0.535002 \t 5.037268 s\n","9 \t 20.200750 \t 9.543231 \t10.008015 \t 0.649505 \t 5.532882 s\n","10 \t 19.627482 \t 9.294244 \t9.951895 \t 0.381343 \t 6.038053 s\n","11 \t 19.583239 \t 9.400303 \t9.863379 \t 0.319556 \t 6.535682 s\n","12 \t 19.468596 \t 9.398821 \t9.869359 \t 0.200417 \t 7.051818 s\n","13 \t 19.691699 \t 9.540558 \t9.718390 \t 0.432752 \t 7.554828 s\n","14 \t 19.204086 \t 9.351962 \t9.601901 \t 0.250224 \t 8.222544 s\n","15 \t 19.084139 \t 9.199450 \t9.612360 \t 0.272329 \t 8.832171 s\n","16 \t 19.081464 \t 9.274800 \t9.530089 \t 0.276574 \t 9.627580 s\n","17 \t 19.279160 \t 9.390193 \t9.537443 \t 0.351523 \t 10.313220 s\n","18 \t 19.146744 \t 9.267701 \t9.583615 \t 0.295429 \t 10.929601 s\n","19 \t 19.149185 \t 9.483928 \t9.459149 \t 0.206108 \t 11.448668 s\n","20 \t 19.489115 \t 9.217549 \t10.091644 \t 0.179922 \t 11.958297 s\n","21 \t 18.856735 \t 9.213246 \t9.502013 \t 0.141476 \t 12.474713 s\n","22 \t 18.894716 \t 9.350417 \t9.341892 \t 0.202407 \t 12.990621 s\n","23 \t 19.307004 \t 9.358604 \t9.784001 \t 0.164398 \t 13.509404 s\n","24 \t 18.924901 \t 9.254759 \t9.395142 \t 0.274999 \t 14.030109 s\n","25 \t 19.341645 \t 9.519998 \t9.576425 \t 0.245223 \t 14.562443 s\n","26 \t 18.690949 \t 9.238492 \t9.285278 \t 0.167179 \t 15.229360 s\n","27 \t 19.007799 \t 9.331609 \t9.434788 \t 0.241402 \t 15.740688 s\n","28 \t 18.824279 \t 9.114621 \t9.448279 \t 0.261378 \t 16.266800 s\n","29 \t 19.108966 \t 9.225329 \t9.521316 \t 0.362322 \t 16.777968 s\n","30 \t 18.808774 \t 9.257650 \t9.396893 \t 0.154232 \t 17.296597 s\n","31 \t 18.970542 \t 9.286392 \t9.342472 \t 0.341678 \t 17.809734 s\n","32 \t 18.942302 \t 9.337140 \t9.450546 \t 0.154615 \t 18.331264 s\n","33 \t 19.011977 \t 9.235178 \t9.399055 \t 0.377744 \t 18.850274 s\n","34 \t 18.831419 \t 9.339907 \t9.305097 \t 0.186416 \t 19.363643 s\n","35 \t 18.846621 \t 9.338332 \t9.307260 \t 0.201028 \t 19.881710 s\n","36 \t 18.686280 \t 9.180732 \t9.327282 \t 0.178265 \t 20.534407 s\n","37 \t 18.642844 \t 8.982330 \t9.418713 \t 0.241801 \t 21.165483 s\n","38 \t 18.782888 \t 9.124404 \t9.437938 \t 0.220546 \t 21.816110 s\n","39 \t 18.630040 \t 9.017920 \t9.436788 \t 0.175332 \t 22.430874 s\n","40 \t 18.605084 \t 9.038172 \t9.357626 \t 0.209286 \t 23.095746 s\n","41 \t 18.932958 \t 9.297201 \t9.492848 \t 0.142909 \t 23.753636 s\n","42 \t 19.120897 \t 9.237364 \t9.582500 \t 0.301033 \t 24.265607 s\n","43 \t 18.774183 \t 9.189504 \t9.398284 \t 0.186395 \t 24.784426 s\n","44 \t 18.708492 \t 9.098396 \t9.448547 \t 0.161549 \t 25.295721 s\n","45 \t 18.780933 \t 9.252725 \t9.256085 \t 0.272122 \t 25.809478 s\n","46 \t 18.563350 \t 9.073522 \t9.345860 \t 0.143968 \t 26.457451 s\n","47 \t 18.321177 \t 9.038117 \t9.113128 \t 0.169932 \t 26.975189 s\n","48 \t 18.635710 \t 9.171311 \t9.136914 \t 0.327484 \t 27.485492 s\n","49 \t 18.196762 \t 9.002660 \t9.085848 \t 0.108254 \t 28.003770 s\n","50 \t 18.875169 \t 9.194357 \t9.284311 \t 0.396502 \t 28.522248 s\n","51 \t 18.662717 \t 9.143208 \t9.344804 \t 0.174705 \t 29.051070 s\n","52 \t 18.573902 \t 8.994555 \t9.260282 \t 0.319064 \t 29.559960 s\n","53 \t 18.377931 \t 9.066320 \t9.142511 \t 0.169099 \t 30.083083 s\n","54 \t 18.417879 \t 8.925466 \t9.208153 \t 0.284261 \t 30.743295 s\n","55 \t 18.547648 \t 9.114087 \t9.282315 \t 0.151246 \t 31.274528 s\n","56 \t 18.533216 \t 9.045906 \t9.319419 \t 0.167891 \t 31.798325 s\n","57 \t 18.551659 \t 9.019235 \t9.283718 \t 0.248706 \t 32.312610 s\n","58 \t 18.395414 \t 8.918097 \t9.314927 \t 0.162391 \t 32.828724 s\n","59 \t 18.327567 \t 9.019365 \t9.164877 \t 0.143325 \t 33.335386 s\n","60 \t 18.534878 \t 9.089015 \t9.334555 \t 0.111308 \t 33.926071 s\n","61 \t 18.632362 \t 9.040008 \t9.435767 \t 0.156587 \t 34.542939 s\n","62 \t 18.483988 \t 9.163384 \t9.184710 \t 0.135894 \t 35.167894 s\n","63 \t 18.212456 \t 8.865697 \t9.196749 \t 0.150010 \t 35.982687 s\n","64 \t 18.457364 \t 9.031691 \t9.177419 \t 0.248253 \t 36.667392 s\n","65 \t 18.334309 \t 8.879379 \t9.157384 \t 0.297545 \t 37.202498 s\n","66 \t 18.596679 \t 9.125124 \t9.280574 \t 0.190981 \t 37.714252 s\n","67 \t 18.320314 \t 8.899056 \t9.194283 \t 0.226976 \t 38.237818 s\n","68 \t 18.193728 \t 8.950876 \t9.083339 \t 0.159514 \t 38.743194 s\n","69 \t 18.339239 \t 8.998827 \t9.213880 \t 0.126533 \t 39.268308 s\n","70 \t 18.393788 \t 9.051818 \t9.208200 \t 0.133769 \t 39.781687 s\n","71 \t 18.298601 \t 8.871367 \t9.343792 \t 0.083441 \t 40.332145 s\n","72 \t 18.250850 \t 8.950182 \t9.164842 \t 0.135826 \t 40.851130 s\n","73 \t 18.075130 \t 8.836805 \t9.096998 \t 0.141327 \t 41.495588 s\n","74 \t 18.095366 \t 8.854681 \t9.125240 \t 0.115445 \t 42.012894 s\n","75 \t 17.985087 \t 8.730696 \t9.042986 \t 0.211406 \t 42.527942 s\n","76 \t 18.106021 \t 8.793032 \t9.115974 \t 0.197015 \t 43.042126 s\n","77 \t 18.362434 \t 9.002365 \t9.148709 \t 0.211361 \t 43.551604 s\n","78 \t 18.172169 \t 8.890556 \t9.148288 \t 0.133325 \t 44.054064 s\n","79 \t 18.160323 \t 8.764874 \t9.282945 \t 0.112505 \t 44.563279 s\n","80 \t 18.107036 \t 8.835913 \t9.049100 \t 0.222022 \t 45.070568 s\n","81 \t 18.007401 \t 8.778363 \t8.989588 \t 0.239449 \t 45.581521 s\n","82 \t 18.043888 \t 8.884361 \t8.990058 \t 0.169468 \t 46.082658 s\n","83 \t 18.179540 \t 8.868294 \t9.185162 \t 0.126084 \t 46.778709 s\n","84 \t 18.270425 \t 8.931305 \t9.110274 \t 0.228847 \t 47.411309 s\n","85 \t 18.107618 \t 8.739292 \t9.167653 \t 0.200674 \t 48.030006 s\n","86 \t 18.085315 \t 8.663901 \t9.143644 \t 0.277769 \t 48.671097 s\n","87 \t 17.991134 \t 8.769428 \t9.071431 \t 0.150274 \t 49.351196 s\n","88 \t 18.214832 \t 8.976979 \t9.055078 \t 0.182775 \t 49.993643 s\n","89 \t 18.198793 \t 8.924070 \t9.108089 \t 0.166635 \t 50.493537 s\n","90 \t 18.148940 \t 8.862546 \t9.158767 \t 0.127627 \t 51.021643 s\n","91 \t 18.023083 \t 8.731973 \t9.154706 \t 0.136405 \t 51.657325 s\n","92 \t 17.822346 \t 8.711483 \t9.002034 \t 0.108828 \t 52.203430 s\n","93 \t 18.015239 \t 8.708147 \t9.075879 \t 0.231213 \t 52.715710 s\n","94 \t 17.931801 \t 8.762047 \t9.027962 \t 0.141792 \t 53.239055 s\n","95 \t 17.889581 \t 8.707885 \t9.048747 \t 0.132948 \t 53.757530 s\n","96 \t 18.005606 \t 8.799753 \t9.008361 \t 0.197492 \t 54.265804 s\n","97 \t 17.988911 \t 8.671435 \t9.104305 \t 0.213170 \t 54.772077 s\n","98 \t 17.670713 \t 8.563028 \t8.999204 \t 0.108481 \t 55.286835 s\n","99 \t 18.063553 \t 8.791362 \t9.150646 \t 0.121545 \t 55.788534 s\n","100 \t 17.821140 \t 8.723043 \t9.000263 \t 0.097833 \t 56.441866 s\n","101 \t 17.737512 \t 8.673989 \t8.919966 \t 0.143556 \t 56.951132 s\n","102 \t 17.949868 \t 8.670430 \t9.171385 \t 0.108054 \t 57.454555 s\n","103 \t 17.979678 \t 8.661047 \t9.174731 \t 0.143901 \t 57.967665 s\n","104 \t 17.809118 \t 8.642866 \t8.999690 \t 0.166563 \t 58.467474 s\n","105 \t 17.662802 \t 8.620619 \t8.946698 \t 0.095485 \t 58.975878 s\n","106 \t 17.812671 \t 8.621779 \t9.043340 \t 0.147551 \t 59.479417 s\n","107 \t 17.871336 \t 8.678904 \t9.021256 \t 0.171177 \t 60.064023 s\n","108 \t 17.780174 \t 8.653105 \t8.973970 \t 0.153099 \t 60.677004 s\n","109 \t 17.581269 \t 8.569293 \t8.898572 \t 0.113405 \t 61.338200 s\n","110 \t 17.528785 \t 8.451672 \t8.948339 \t 0.128774 \t 62.147071 s\n","111 \t 17.531064 \t 8.546883 \t8.892891 \t 0.091291 \t 62.801807 s\n","112 \t 17.548402 \t 8.620761 \t8.855388 \t 0.072253 \t 63.314590 s\n","113 \t 17.627859 \t 8.540096 \t8.939663 \t 0.148100 \t 63.824341 s\n","114 \t 17.667858 \t 8.541245 \t8.861320 \t 0.265293 \t 64.344304 s\n","115 \t 17.659280 \t 8.502707 \t9.053004 \t 0.103569 \t 64.855438 s\n","116 \t 17.659019 \t 8.555584 \t8.965460 \t 0.137976 \t 65.373368 s\n","117 \t 17.444290 \t 8.375353 \t8.969153 \t 0.099784 \t 65.881052 s\n","118 \t 17.600019 \t 8.531930 \t8.993191 \t 0.074900 \t 66.389088 s\n","119 \t 17.490062 \t 8.571966 \t8.853957 \t 0.064139 \t 66.894650 s\n","120 \t 17.385730 \t 8.414026 \t8.846356 \t 0.125346 \t 67.525909 s\n","121 \t 17.492446 \t 8.437322 \t8.959629 \t 0.095496 \t 68.029509 s\n","122 \t 17.476716 \t 8.464192 \t8.807004 \t 0.205520 \t 68.540605 s\n","123 \t 17.965650 \t 8.704582 \t9.132834 \t 0.128234 \t 69.047475 s\n","124 \t 17.535029 \t 8.523183 \t8.870124 \t 0.141722 \t 69.558445 s\n","125 \t 17.523540 \t 8.586655 \t8.808224 \t 0.128662 \t 70.058494 s\n","126 \t 17.426473 \t 8.475742 \t8.890099 \t 0.060631 \t 70.564682 s\n","127 \t 17.443910 \t 8.510102 \t8.779472 \t 0.154336 \t 71.073675 s\n","128 \t 17.545463 \t 8.481755 \t8.934035 \t 0.129673 \t 71.587227 s\n","129 \t 17.417847 \t 8.362911 \t8.927104 \t 0.127832 \t 72.226823 s\n","130 \t 17.613215 \t 8.491302 \t9.037397 \t 0.084516 \t 72.736831 s\n","131 \t 17.342149 \t 8.399431 \t8.821204 \t 0.121512 \t 73.395730 s\n","132 \t 17.630797 \t 8.597596 \t8.954176 \t 0.079025 \t 74.039113 s\n","133 \t 17.667114 \t 8.538372 \t8.967778 \t 0.160964 \t 74.681068 s\n","134 \t 17.409958 \t 8.477746 \t8.839121 \t 0.093090 \t 75.327344 s\n","135 \t 17.385133 \t 8.539750 \t8.754922 \t 0.090460 \t 75.966268 s\n","136 \t 17.421543 \t 8.480362 \t8.755723 \t 0.185460 \t 76.471030 s\n","137 \t 17.450227 \t 8.370546 \t8.959332 \t 0.120348 \t 77.127895 s\n","138 \t 17.326334 \t 8.546421 \t8.711180 \t 0.068733 \t 77.631599 s\n","139 \t 17.225073 \t 8.370309 \t8.749840 \t 0.104923 \t 78.153570 s\n","140 \t 17.586728 \t 8.535072 \t8.926591 \t 0.125064 \t 78.654603 s\n","141 \t 17.691690 \t 8.507263 \t9.081903 \t 0.102524 \t 79.177159 s\n","142 \t 17.582665 \t 8.450058 \t8.970445 \t 0.162162 \t 79.674369 s\n","143 \t 17.320390 \t 8.355665 \t8.892693 \t 0.072032 \t 80.193237 s\n","144 \t 17.645128 \t 8.561471 \t8.942194 \t 0.141462 \t 80.699694 s\n","145 \t 17.332514 \t 8.420992 \t8.801227 \t 0.110296 \t 81.231220 s\n","146 \t 17.335920 \t 8.436384 \t8.816212 \t 0.083325 \t 81.738891 s\n","147 \t 17.517947 \t 8.445778 \t8.940964 \t 0.131205 \t 82.432167 s\n","148 \t 17.251712 \t 8.312341 \t8.850745 \t 0.088626 \t 82.954506 s\n","149 \t 17.170420 \t 8.420563 \t8.684065 \t 0.065793 \t 83.472186 s\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 162/162 [00:12<00:00, 12.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Link Prediction on Validation Set (Tri)\n","MRR: 0.3536\n","Hit@10: 0.5068\n","Hit@3: 0.3664\n","Hit@1: 0.2740\n","Link Prediction on Validation Set (All)\n","MRR: 0.3536\n","Hit@10: 0.5068\n","Hit@3: 0.3664\n","Hit@1: 0.2740\n","Relation Prediction on Validation Set (Tri)\n","MRR: 0.4028\n","Hit@10: 0.6296\n","Hit@3: 0.4753\n","Hit@1: 0.2654\n","Relation Prediction on Validation Set (All)\n","MRR: 0.4028\n","Hit@10: 0.6296\n","Hit@3: 0.4753\n","Hit@1: 0.2654\n","Numeric Value Prediction on Validation Set (Tri)\n","RMSE: 0.0987\n","Numeric Value Prediction on Validation Set (All)\n","RMSE: 0.0987\n","150 \t 17.868353 \t 8.677914 \t8.947998 \t 0.242441 \t 101.295761 s\n","151 \t 19.132241 \t 9.266734 \t9.482562 \t 0.382946 \t 101.901613 s\n","152 \t 18.827649 \t 9.134531 \t9.471701 \t 0.221417 \t 102.415512 s\n","153 \t 18.630645 \t 9.009855 \t9.484425 \t 0.136365 \t 102.929878 s\n","154 \t 18.259897 \t 8.782048 \t9.358515 \t 0.119335 \t 103.431006 s\n","155 \t 17.701079 \t 8.522070 \t9.099186 \t 0.079824 \t 103.946323 s\n","156 \t 17.747849 \t 8.600208 \t9.054945 \t 0.092696 \t 104.582286 s\n","157 \t 18.041537 \t 8.756200 \t9.154985 \t 0.130352 \t 105.105457 s\n","158 \t 17.716996 \t 8.566486 \t9.020068 \t 0.130442 \t 105.608848 s\n","159 \t 17.687698 \t 8.542911 \t9.044781 \t 0.100006 \t 106.132066 s\n","160 \t 17.862716 \t 8.669654 \t9.059518 \t 0.133544 \t 106.632908 s\n","161 \t 17.493247 \t 8.574603 \t8.848077 \t 0.070566 \t 107.151862 s\n","162 \t 17.373188 \t 8.467884 \t8.817792 \t 0.087513 \t 107.654270 s\n","163 \t 17.408578 \t 8.512595 \t8.746078 \t 0.149905 \t 108.261226 s\n","164 \t 17.439080 \t 8.464454 \t8.870622 \t 0.104005 \t 108.901188 s\n","165 \t 17.480724 \t 8.410801 \t8.896544 \t 0.173380 \t 109.671479 s\n","166 \t 17.207241 \t 8.336162 \t8.769835 \t 0.101244 \t 110.301120 s\n","167 \t 17.624996 \t 8.554142 \t8.846050 \t 0.224804 \t 110.933603 s\n","168 \t 17.447335 \t 8.404441 \t8.876626 \t 0.166267 \t 111.685380 s\n","169 \t 17.263579 \t 8.402548 \t8.739143 \t 0.121887 \t 112.658549 s\n","170 \t 17.255960 \t 8.375519 \t8.753485 \t 0.126955 \t 113.870382 s\n","171 \t 17.283491 \t 8.429090 \t8.748435 \t 0.105965 \t 115.057760 s\n","172 \t 17.038964 \t 8.354690 \t8.582901 \t 0.101373 \t 115.858199 s\n","173 \t 17.109991 \t 8.296922 \t8.678267 \t 0.134801 \t 116.492270 s\n","174 \t 17.077576 \t 8.275822 \t8.693437 \t 0.108318 \t 117.293158 s\n","175 \t 17.072560 \t 8.253194 \t8.655243 \t 0.164124 \t 117.854706 s\n","176 \t 16.988392 \t 8.186645 \t8.691678 \t 0.110068 \t 118.382829 s\n","177 \t 17.122629 \t 8.339455 \t8.654790 \t 0.128384 \t 118.934891 s\n","178 \t 17.028085 \t 8.204753 \t8.656506 \t 0.166827 \t 119.464373 s\n","179 \t 17.010211 \t 8.226789 \t8.644237 \t 0.139185 \t 119.996533 s\n","180 \t 16.704601 \t 8.193470 \t8.409984 \t 0.101147 \t 120.614782 s\n","181 \t 16.901355 \t 8.132867 \t8.646003 \t 0.122484 \t 121.140388 s\n","182 \t 16.917435 \t 8.201817 \t8.621332 \t 0.094285 \t 121.666736 s\n","183 \t 16.832233 \t 8.184435 \t8.514182 \t 0.133617 \t 122.229979 s\n","184 \t 16.933788 \t 8.137254 \t8.525265 \t 0.271269 \t 122.924593 s\n","185 \t 16.790320 \t 8.320847 \t8.410030 \t 0.059443 \t 123.442974 s\n","186 \t 16.414656 \t 8.116713 \t8.218824 \t 0.079119 \t 124.007981 s\n","187 \t 16.923903 \t 8.216689 \t8.579858 \t 0.127356 \t 124.555066 s\n","188 \t 16.936981 \t 8.254562 \t8.602043 \t 0.080376 \t 125.103061 s\n","189 \t 16.505728 \t 8.060060 \t8.382758 \t 0.062910 \t 125.721622 s\n","190 \t 16.899027 \t 8.237443 \t8.586990 \t 0.074594 \t 126.388079 s\n","191 \t 16.693939 \t 8.187555 \t8.430229 \t 0.076155 \t 127.063356 s\n","192 \t 16.558667 \t 8.051223 \t8.433126 \t 0.074319 \t 127.745886 s\n","193 \t 16.789654 \t 8.247709 \t8.455154 \t 0.086791 \t 128.522442 s\n","194 \t 16.701162 \t 8.090327 \t8.525763 \t 0.085073 \t 129.179560 s\n","195 \t 16.383694 \t 7.992501 \t8.304135 \t 0.087058 \t 129.687111 s\n","196 \t 16.543797 \t 8.125127 \t8.356367 \t 0.062302 \t 130.219316 s\n","197 \t 16.292556 \t 8.053794 \t8.198542 \t 0.040219 \t 130.721612 s\n","198 \t 16.657392 \t 8.057284 \t8.421546 \t 0.178561 \t 131.262562 s\n","199 \t 16.615612 \t 8.176755 \t8.322465 \t 0.116391 \t 131.774280 s\n","200 \t 16.639962 \t 8.182009 \t8.351243 \t 0.106711 \t 132.313335 s\n","201 \t 16.304919 \t 7.985648 \t8.192184 \t 0.127087 \t 132.829336 s\n","202 \t 16.484794 \t 8.132813 \t8.218594 \t 0.133385 \t 133.350456 s\n","203 \t 16.511292 \t 8.033960 \t8.387404 \t 0.089928 \t 133.863729 s\n","204 \t 16.336346 \t 8.029006 \t8.196100 \t 0.111239 \t 134.503275 s\n","205 \t 16.562724 \t 8.036183 \t8.417265 \t 0.109277 \t 135.022783 s\n","206 \t 16.164634 \t 7.997963 \t8.100091 \t 0.066580 \t 135.525730 s\n","207 \t 16.446350 \t 7.998607 \t8.348933 \t 0.098810 \t 136.038193 s\n","208 \t 16.155519 \t 7.881618 \t8.170005 \t 0.103896 \t 136.537390 s\n","209 \t 16.272624 \t 7.908212 \t8.227609 \t 0.136803 \t 137.057506 s\n","210 \t 16.145251 \t 7.889006 \t8.197945 \t 0.058300 \t 137.565063 s\n","211 \t 16.113257 \t 7.815331 \t8.177241 \t 0.120686 \t 138.072612 s\n","212 \t 16.205542 \t 7.979662 \t8.087752 \t 0.138127 \t 138.796201 s\n","213 \t 16.347714 \t 8.051387 \t8.186386 \t 0.109941 \t 139.425253 s\n","214 \t 16.136597 \t 7.877164 \t8.146605 \t 0.112827 \t 140.038407 s\n","215 \t 16.167587 \t 7.969840 \t8.056312 \t 0.141436 \t 140.680316 s\n","216 \t 16.163245 \t 7.992454 \t8.075919 \t 0.094874 \t 141.377247 s\n","217 \t 16.175746 \t 8.029591 \t8.097343 \t 0.048812 \t 141.943799 s\n","218 \t 16.010249 \t 7.875133 \t8.025724 \t 0.109391 \t 142.476689 s\n","219 \t 16.008876 \t 7.881509 \t8.070915 \t 0.056452 \t 143.016088 s\n","220 \t 15.839080 \t 7.871053 \t7.917271 \t 0.050756 \t 143.549782 s\n","221 \t 16.116293 \t 7.951190 \t8.100091 \t 0.065013 \t 144.207209 s\n","222 \t 15.910556 \t 7.894087 \t7.964133 \t 0.052337 \t 144.717515 s\n","223 \t 15.754834 \t 7.774494 \t7.929808 \t 0.050532 \t 145.235204 s\n","224 \t 15.711930 \t 7.771706 \t7.882347 \t 0.057876 \t 145.742754 s\n","225 \t 15.759623 \t 7.755616 \t7.965492 \t 0.038514 \t 146.248753 s\n","226 \t 15.728014 \t 7.776635 \t7.903042 \t 0.048337 \t 146.755852 s\n","227 \t 15.675307 \t 7.695578 \t7.915873 \t 0.063857 \t 147.259618 s\n","228 \t 15.920855 \t 7.775642 \t8.101127 \t 0.044086 \t 147.766542 s\n","229 \t 15.744682 \t 7.765237 \t7.936163 \t 0.043282 \t 148.272299 s\n","230 \t 15.959022 \t 7.927678 \t7.966009 \t 0.065334 \t 148.783207 s\n","231 \t 15.842536 \t 7.838826 \t7.935861 \t 0.067849 \t 149.440456 s\n","232 \t 15.668188 \t 7.645314 \t7.958855 \t 0.064018 \t 149.961058 s\n","233 \t 15.705293 \t 7.789145 \t7.874750 \t 0.041398 \t 150.473564 s\n","234 \t 15.444147 \t 7.750033 \t7.644463 \t 0.049651 \t 151.002695 s\n","235 \t 15.570307 \t 7.686304 \t7.800246 \t 0.083758 \t 151.510059 s\n","236 \t 15.629147 \t 7.677675 \t7.856500 \t 0.094971 \t 152.164485 s\n","237 \t 15.584433 \t 7.681572 \t7.864670 \t 0.038190 \t 152.787142 s\n","238 \t 15.648518 \t 7.706897 \t7.896941 \t 0.044680 \t 153.404211 s\n","239 \t 15.582729 \t 7.740921 \t7.780087 \t 0.061722 \t 154.057679 s\n","240 \t 15.627227 \t 7.652851 \t7.884144 \t 0.090232 \t 154.701551 s\n","241 \t 15.812262 \t 7.856514 \t7.904314 \t 0.051433 \t 155.346020 s\n","242 \t 15.459689 \t 7.687465 \t7.700384 \t 0.071840 \t 155.854919 s\n","243 \t 15.473164 \t 7.778527 \t7.647989 \t 0.046648 \t 156.363076 s\n","244 \t 15.401442 \t 7.583496 \t7.752401 \t 0.065544 \t 156.871548 s\n","245 \t 15.504953 \t 7.712724 \t7.735525 \t 0.056704 \t 157.390501 s\n","246 \t 15.428403 \t 7.760024 \t7.586300 \t 0.082079 \t 157.891144 s\n","247 \t 15.478788 \t 7.616286 \t7.780500 \t 0.082002 \t 158.403176 s\n","248 \t 15.106295 \t 7.448342 \t7.617285 \t 0.040669 \t 159.049436 s\n","249 \t 15.352836 \t 7.644250 \t7.658832 \t 0.049754 \t 159.553337 s\n","250 \t 15.250900 \t 7.500137 \t7.714009 \t 0.036754 \t 160.066721 s\n","251 \t 15.425658 \t 7.673155 \t7.647222 \t 0.105281 \t 160.571708 s\n","252 \t 15.495574 \t 7.670693 \t7.771633 \t 0.053248 \t 161.085820 s\n","253 \t 15.330580 \t 7.572588 \t7.700104 \t 0.057888 \t 161.596736 s\n","254 \t 15.510702 \t 7.788668 \t7.674999 \t 0.047035 \t 162.116669 s\n","255 \t 15.400193 \t 7.648067 \t7.713803 \t 0.038322 \t 162.627448 s\n","256 \t 15.023612 \t 7.481724 \t7.497612 \t 0.044277 \t 163.144711 s\n","257 \t 15.212820 \t 7.555209 \t7.604674 \t 0.052936 \t 163.651043 s\n","258 \t 15.246246 \t 7.605862 \t7.593510 \t 0.046874 \t 164.303143 s\n","259 \t 15.161377 \t 7.618057 \t7.504926 \t 0.038395 \t 164.875381 s\n","260 \t 15.331781 \t 7.618239 \t7.674251 \t 0.039291 \t 165.511404 s\n","261 \t 15.234481 \t 7.563000 \t7.619971 \t 0.051509 \t 166.123085 s\n","262 \t 15.275180 \t 7.554457 \t7.663965 \t 0.056758 \t 166.775831 s\n","263 \t 15.144868 \t 7.516482 \t7.591582 \t 0.036804 \t 167.475351 s\n","264 \t 15.041462 \t 7.474722 \t7.512125 \t 0.054615 \t 168.054656 s\n","265 \t 15.068266 \t 7.440056 \t7.585756 \t 0.042455 \t 168.568215 s\n","266 \t 14.902744 \t 7.482690 \t7.384129 \t 0.035926 \t 169.076263 s\n","267 \t 15.073832 \t 7.478716 \t7.548133 \t 0.046982 \t 169.581606 s\n","268 \t 14.976405 \t 7.521722 \t7.394615 \t 0.060068 \t 170.222972 s\n","269 \t 15.099683 \t 7.428660 \t7.625662 \t 0.045360 \t 170.725210 s\n","270 \t 15.265246 \t 7.617768 \t7.564673 \t 0.082806 \t 171.240752 s\n","271 \t 15.038118 \t 7.447989 \t7.560441 \t 0.029688 \t 171.745109 s\n","272 \t 14.940287 \t 7.462172 \t7.437886 \t 0.040230 \t 172.253540 s\n","273 \t 15.205051 \t 7.495305 \t7.648696 \t 0.061050 \t 172.782505 s\n","274 \t 14.900370 \t 7.468099 \t7.393174 \t 0.039097 \t 173.316439 s\n","275 \t 14.882894 \t 7.360721 \t7.495125 \t 0.027048 \t 173.834657 s\n","276 \t 15.103671 \t 7.520653 \t7.535543 \t 0.047474 \t 174.340113 s\n","277 \t 15.080860 \t 7.514666 \t7.518489 \t 0.047706 \t 174.861768 s\n","278 \t 14.901046 \t 7.300898 \t7.570513 \t 0.029635 \t 175.499832 s\n","279 \t 15.064024 \t 7.384827 \t7.609582 \t 0.069615 \t 176.026708 s\n","280 \t 15.030866 \t 7.506385 \t7.476655 \t 0.047826 \t 176.528559 s\n","281 \t 15.210310 \t 7.594881 \t7.584081 \t 0.031347 \t 177.049209 s\n","282 \t 14.855453 \t 7.399776 \t7.415985 \t 0.039692 \t 177.550494 s\n","283 \t 14.991977 \t 7.524150 \t7.424430 \t 0.043397 \t 178.159811 s\n","284 \t 15.137856 \t 7.541044 \t7.567004 \t 0.029809 \t 178.784872 s\n","285 \t 14.620814 \t 7.286628 \t7.277471 \t 0.056715 \t 179.410901 s\n","286 \t 14.772359 \t 7.366262 \t7.358698 \t 0.047398 \t 180.235311 s\n","287 \t 14.827551 \t 7.367742 \t7.406067 \t 0.053743 \t 180.852784 s\n","288 \t 14.910002 \t 7.462912 \t7.416769 \t 0.030321 \t 181.374374 s\n","289 \t 14.885003 \t 7.364056 \t7.475388 \t 0.045558 \t 181.879816 s\n","290 \t 14.880659 \t 7.393891 \t7.451654 \t 0.035113 \t 182.397816 s\n","291 \t 14.841824 \t 7.417425 \t7.373946 \t 0.050452 \t 182.900269 s\n","292 \t 14.970109 \t 7.408086 \t7.532661 \t 0.029363 \t 183.431348 s\n","293 \t 14.860729 \t 7.358485 \t7.446860 \t 0.055384 \t 183.939002 s\n","294 \t 14.892092 \t 7.445068 \t7.414572 \t 0.032453 \t 184.457061 s\n","295 \t 14.772166 \t 7.344850 \t7.381552 \t 0.045765 \t 185.117941 s\n","296 \t 14.842563 \t 7.419137 \t7.362331 \t 0.061095 \t 185.617609 s\n","297 \t 14.992394 \t 7.427487 \t7.528283 \t 0.036624 \t 186.134724 s\n","298 \t 14.731041 \t 7.315136 \t7.383398 \t 0.032507 \t 186.637246 s\n","299 \t 14.701939 \t 7.383676 \t7.266991 \t 0.051272 \t 187.149395 s\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 162/162 [00:12<00:00, 12.93it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Link Prediction on Validation Set (Tri)\n","MRR: 0.3659\n","Hit@10: 0.5240\n","Hit@3: 0.3938\n","Hit@1: 0.2774\n","Link Prediction on Validation Set (All)\n","MRR: 0.3659\n","Hit@10: 0.5240\n","Hit@3: 0.3938\n","Hit@1: 0.2774\n","Relation Prediction on Validation Set (Tri)\n","MRR: 0.4147\n","Hit@10: 0.6420\n","Hit@3: 0.5247\n","Hit@1: 0.2654\n","Relation Prediction on Validation Set (All)\n","MRR: 0.4147\n","Hit@10: 0.6420\n","Hit@3: 0.5247\n","Hit@1: 0.2654\n","Numeric Value Prediction on Validation Set (Tri)\n","RMSE: 0.0748\n","Numeric Value Prediction on Validation Set (All)\n","RMSE: 0.0748\n","300 \t 14.708070 \t 7.329949 \t7.351596 \t 0.026526 \t 201.374145 s\n","301 \t 14.664565 \t 7.291082 \t7.350572 \t 0.022910 \t 201.887486 s\n","302 \t 14.761058 \t 7.440122 \t7.287894 \t 0.033042 \t 202.390599 s\n","303 \t 14.705049 \t 7.252424 \t7.429783 \t 0.022842 \t 202.907711 s\n","304 \t 14.698909 \t 7.294232 \t7.376441 \t 0.028236 \t 203.450090 s\n","305 \t 14.721300 \t 7.374624 \t7.322948 \t 0.023728 \t 204.144908 s\n","306 \t 14.855437 \t 7.390705 \t7.441962 \t 0.022771 \t 204.800435 s\n","307 \t 14.820039 \t 7.469416 \t7.327191 \t 0.023432 \t 205.420828 s\n","308 \t 14.891043 \t 7.381316 \t7.485825 \t 0.023901 \t 206.063561 s\n","309 \t 14.874113 \t 7.425958 \t7.422345 \t 0.025810 \t 206.757149 s\n","310 \t 14.678485 \t 7.242547 \t7.403914 \t 0.032025 \t 207.366415 s\n","311 \t 14.671820 \t 7.305859 \t7.324799 \t 0.041163 \t 207.879468 s\n","312 \t 14.670117 \t 7.376559 \t7.259897 \t 0.033661 \t 208.395855 s\n","313 \t 14.868959 \t 7.385709 \t7.453947 \t 0.029304 \t 208.901460 s\n","314 \t 14.737029 \t 7.365286 \t7.344907 \t 0.026836 \t 209.565830 s\n","315 \t 14.635922 \t 7.264537 \t7.353549 \t 0.017835 \t 210.078089 s\n","316 \t 14.854554 \t 7.382150 \t7.441031 \t 0.031373 \t 210.583869 s\n","317 \t 14.577354 \t 7.328497 \t7.225629 \t 0.023228 \t 211.129650 s\n","318 \t 14.739652 \t 7.356698 \t7.345309 \t 0.037645 \t 211.638436 s\n","319 \t 14.537708 \t 7.202358 \t7.302600 \t 0.032750 \t 212.336412 s\n","320 \t 14.591219 \t 7.279099 \t7.263987 \t 0.048134 \t 213.430702 s\n","321 \t 14.623713 \t 7.371420 \t7.223673 \t 0.028620 \t 214.038396 s\n","322 \t 14.768463 \t 7.365162 \t7.387143 \t 0.016156 \t 214.651890 s\n","323 \t 14.736966 \t 7.412443 \t7.294650 \t 0.029873 \t 215.275742 s\n","324 \t 14.625210 \t 7.175108 \t7.411920 \t 0.038182 \t 216.046968 s\n","325 \t 14.530428 \t 7.211797 \t7.291173 \t 0.027458 \t 216.652867 s\n","326 \t 14.698006 \t 7.309037 \t7.365100 \t 0.023868 \t 217.448703 s\n","327 \t 14.436328 \t 7.173094 \t7.238242 \t 0.024993 \t 218.501040 s\n","328 \t 14.566338 \t 7.277124 \t7.257532 \t 0.031682 \t 219.762861 s\n","329 \t 14.557749 \t 7.257992 \t7.280926 \t 0.018830 \t 220.877840 s\n","330 \t 14.425148 \t 7.193349 \t7.205434 \t 0.026364 \t 221.541016 s\n","331 \t 14.731963 \t 7.315528 \t7.392802 \t 0.023633 \t 222.164211 s\n","332 \t 14.511378 \t 7.193335 \t7.283869 \t 0.034174 \t 222.824087 s\n","333 \t 14.537323 \t 7.222028 \t7.297269 \t 0.018025 \t 223.377496 s\n","334 \t 14.561067 \t 7.199611 \t7.322285 \t 0.039171 \t 223.941002 s\n","335 \t 14.409347 \t 7.198401 \t7.192066 \t 0.018880 \t 224.474691 s\n","336 \t 14.599464 \t 7.339850 \t7.239537 \t 0.020077 \t 225.016132 s\n","337 \t 14.719266 \t 7.334462 \t7.346491 \t 0.038313 \t 225.554552 s\n","338 \t 14.559014 \t 7.305290 \t7.219725 \t 0.033999 \t 226.089701 s\n","339 \t 14.640095 \t 7.273532 \t7.334415 \t 0.032147 \t 226.646808 s\n","340 \t 14.512472 \t 7.241797 \t7.234736 \t 0.035938 \t 227.190211 s\n","341 \t 14.517082 \t 7.155503 \t7.344659 \t 0.016920 \t 227.880673 s\n","342 \t 14.443278 \t 7.215437 \t7.204154 \t 0.023688 \t 228.443406 s\n","343 \t 14.332856 \t 7.142698 \t7.164061 \t 0.026096 \t 228.984374 s\n","344 \t 14.413955 \t 7.234081 \t7.159259 \t 0.020616 \t 229.520886 s\n","345 \t 14.541768 \t 7.260897 \t7.251503 \t 0.029368 \t 230.096090 s\n","346 \t 14.542409 \t 7.247248 \t7.276661 \t 0.018500 \t 230.627879 s\n","347 \t 14.500839 \t 7.215550 \t7.261028 \t 0.024260 \t 231.243589 s\n","348 \t 14.507475 \t 7.251887 \t7.234935 \t 0.020653 \t 231.909050 s\n","349 \t 14.360997 \t 7.150296 \t7.174119 \t 0.036582 \t 232.581251 s\n","350 \t 14.565526 \t 7.295835 \t7.244146 \t 0.025545 \t 233.256545 s\n","351 \t 14.512579 \t 7.213542 \t7.272482 \t 0.026556 \t 234.168357 s\n","352 \t 14.466179 \t 7.250123 \t7.198746 \t 0.017310 \t 234.697979 s\n","353 \t 14.438779 \t 7.130257 \t7.287012 \t 0.021510 \t 235.216474 s\n","354 \t 14.442862 \t 7.287871 \t7.122857 \t 0.032134 \t 235.734126 s\n","355 \t 14.462748 \t 7.199314 \t7.249547 \t 0.013888 \t 236.241172 s\n","356 \t 14.416676 \t 7.156665 \t7.238891 \t 0.021120 \t 236.769081 s\n","357 \t 14.507971 \t 7.227074 \t7.263808 \t 0.017089 \t 237.283942 s\n","358 \t 14.353034 \t 7.111485 \t7.224607 \t 0.016942 \t 237.794661 s\n","359 \t 14.562315 \t 7.286905 \t7.253430 \t 0.021980 \t 238.300483 s\n","360 \t 14.396368 \t 7.202119 \t7.180371 \t 0.013878 \t 238.820597 s\n","361 \t 14.376713 \t 7.203475 \t7.157813 \t 0.015425 \t 239.461570 s\n","362 \t 14.558717 \t 7.359703 \t7.175584 \t 0.023430 \t 239.963693 s\n","363 \t 14.464138 \t 7.158712 \t7.285760 \t 0.019666 \t 240.473144 s\n","364 \t 14.537000 \t 7.245540 \t7.271094 \t 0.020365 \t 240.984085 s\n","365 \t 14.411500 \t 7.109587 \t7.285759 \t 0.016155 \t 241.503783 s\n","366 \t 14.383917 \t 7.169132 \t7.199730 \t 0.015055 \t 242.013352 s\n","367 \t 14.164120 \t 7.076127 \t7.066727 \t 0.021267 \t 242.525505 s\n","368 \t 14.462974 \t 7.169266 \t7.275905 \t 0.017803 \t 243.034554 s\n","369 \t 14.370538 \t 7.075297 \t7.274078 \t 0.021164 \t 243.541693 s\n","370 \t 14.366929 \t 7.161230 \t7.179856 \t 0.025842 \t 244.203527 s\n","371 \t 14.305231 \t 7.189150 \t7.097473 \t 0.018608 \t 244.862046 s\n","372 \t 14.260387 \t 7.084132 \t7.156166 \t 0.020089 \t 245.479300 s\n","373 \t 14.515298 \t 7.226876 \t7.266485 \t 0.021937 \t 246.163417 s\n","374 \t 14.218226 \t 7.053027 \t7.142812 \t 0.022387 \t 246.858397 s\n","375 \t 14.307574 \t 7.115740 \t7.174729 \t 0.017106 \t 247.475147 s\n","376 \t 14.424109 \t 7.160265 \t7.247130 \t 0.016713 \t 247.992121 s\n","377 \t 14.354263 \t 7.204764 \t7.129655 \t 0.019844 \t 248.492029 s\n","378 \t 14.280103 \t 7.180259 \t7.077372 \t 0.022472 \t 249.137882 s\n","379 \t 14.467279 \t 7.213036 \t7.228736 \t 0.025507 \t 249.651011 s\n","380 \t 14.502185 \t 7.218011 \t7.258041 \t 0.026134 \t 250.182815 s\n","381 \t 14.262449 \t 7.112580 \t7.126536 \t 0.023334 \t 250.689493 s\n","382 \t 14.337019 \t 7.089101 \t7.222349 \t 0.025568 \t 251.209496 s\n","383 \t 14.504755 \t 7.202367 \t7.273543 \t 0.028845 \t 251.716196 s\n","384 \t 14.291728 \t 7.159082 \t7.111902 \t 0.020745 \t 252.247387 s\n","385 \t 14.255041 \t 7.136269 \t7.101537 \t 0.017235 \t 252.760588 s\n","386 \t 14.467677 \t 7.243182 \t7.202438 \t 0.022057 \t 253.290498 s\n","387 \t 14.326401 \t 7.141522 \t7.168564 \t 0.016314 \t 253.806195 s\n","388 \t 14.548043 \t 7.188670 \t7.340559 \t 0.018814 \t 254.466936 s\n","389 \t 14.394826 \t 7.058775 \t7.313956 \t 0.022095 \t 254.987124 s\n","390 \t 14.378957 \t 7.191411 \t7.169399 \t 0.018147 \t 255.495723 s\n","391 \t 14.304388 \t 7.181911 \t7.108448 \t 0.014028 \t 256.003589 s\n","392 \t 14.197264 \t 7.072904 \t7.104673 \t 0.019686 \t 256.514939 s\n","393 \t 14.302674 \t 7.159675 \t7.126853 \t 0.016146 \t 257.029655 s\n","394 \t 14.221520 \t 7.065411 \t7.127513 \t 0.028596 \t 257.612592 s\n","395 \t 14.324033 \t 7.139828 \t7.167572 \t 0.016633 \t 258.259266 s\n","396 \t 14.418026 \t 7.249156 \t7.155937 \t 0.012933 \t 258.880989 s\n","397 \t 14.306253 \t 7.132691 \t7.156355 \t 0.017206 \t 259.537121 s\n","398 \t 14.309995 \t 7.058935 \t7.236714 \t 0.014346 \t 260.374579 s\n","399 \t 14.213615 \t 7.130147 \t7.068286 \t 0.015182 \t 260.885640 s\n","400 \t 14.276769 \t 7.169139 \t7.090065 \t 0.017564 \t 261.403182 s\n","401 \t 14.316534 \t 7.149987 \t7.152006 \t 0.014541 \t 261.920080 s\n","402 \t 14.229879 \t 7.071141 \t7.131374 \t 0.027363 \t 262.444184 s\n","403 \t 14.215798 \t 7.023145 \t7.176526 \t 0.016126 \t 262.952575 s\n","404 \t 14.222099 \t 7.060420 \t7.145181 \t 0.016498 \t 263.479692 s\n","405 \t 14.201794 \t 7.093925 \t7.090278 \t 0.017590 \t 264.015750 s\n","406 \t 14.210952 \t 7.079139 \t7.114448 \t 0.017365 \t 264.550922 s\n","407 \t 14.395561 \t 7.111094 \t7.265497 \t 0.018970 \t 265.188977 s\n","408 \t 14.368546 \t 7.198074 \t7.155754 \t 0.014718 \t 265.701273 s\n","409 \t 14.324605 \t 7.222591 \t7.079916 \t 0.022098 \t 266.206933 s\n","410 \t 14.255819 \t 7.113913 \t7.119195 \t 0.022711 \t 266.710315 s\n","411 \t 14.234204 \t 7.159004 \t7.056703 \t 0.018497 \t 267.220693 s\n","412 \t 14.284328 \t 7.102532 \t7.169615 \t 0.012180 \t 267.724514 s\n","413 \t 14.344400 \t 7.189239 \t7.143122 \t 0.012039 \t 268.233917 s\n","414 \t 14.302053 \t 7.165339 \t7.117236 \t 0.019478 \t 268.739912 s\n","415 \t 14.360271 \t 7.208149 \t7.136918 \t 0.015205 \t 269.396686 s\n","416 \t 14.292561 \t 7.128764 \t7.148712 \t 0.015085 \t 269.926670 s\n","417 \t 14.182117 \t 7.045251 \t7.128026 \t 0.008840 \t 270.500521 s\n","418 \t 14.235192 \t 7.123724 \t7.097683 \t 0.013785 \t 271.175297 s\n","419 \t 14.250485 \t 7.032988 \t7.203380 \t 0.014117 \t 271.829508 s\n","420 \t 14.286008 \t 7.121991 \t7.150809 \t 0.013208 \t 272.450654 s\n","421 \t 14.335064 \t 7.169221 \t7.148957 \t 0.016886 \t 273.150520 s\n","422 \t 14.305364 \t 7.156717 \t7.136451 \t 0.012196 \t 273.771114 s\n","423 \t 14.419664 \t 7.159413 \t7.246311 \t 0.013940 \t 274.282230 s\n","424 \t 14.052541 \t 6.986354 \t7.045993 \t 0.020194 \t 274.802982 s\n","425 \t 14.429183 \t 7.216042 \t7.195544 \t 0.017597 \t 275.453215 s\n","426 \t 14.407804 \t 7.187050 \t7.195574 \t 0.025179 \t 275.978338 s\n","427 \t 14.175770 \t 7.124908 \t7.040473 \t 0.010389 \t 276.478803 s\n","428 \t 14.390022 \t 7.168383 \t7.205130 \t 0.016510 \t 277.003542 s\n","429 \t 14.301243 \t 7.161229 \t7.126424 \t 0.013590 \t 277.505360 s\n","430 \t 14.370406 \t 7.199015 \t7.150631 \t 0.020761 \t 278.017867 s\n","431 \t 14.409331 \t 7.147626 \t7.232409 \t 0.029296 \t 278.522474 s\n","432 \t 14.373241 \t 7.234293 \t7.123289 \t 0.015659 \t 279.031007 s\n","433 \t 14.223213 \t 7.120539 \t7.088285 \t 0.014389 \t 279.548490 s\n","434 \t 14.292747 \t 7.125701 \t7.154922 \t 0.012124 \t 280.062248 s\n","435 \t 14.328996 \t 7.180557 \t7.136238 \t 0.012201 \t 280.706085 s\n","436 \t 14.389015 \t 7.174341 \t7.195990 \t 0.018685 \t 281.222632 s\n","437 \t 14.221037 \t 7.099106 \t7.109307 \t 0.012625 \t 281.727171 s\n","438 \t 14.279556 \t 7.193031 \t7.073610 \t 0.012915 \t 282.236450 s\n","439 \t 14.382457 \t 7.137221 \t7.226425 \t 0.018810 \t 282.743861 s\n","440 \t 14.342098 \t 7.206094 \t7.124066 \t 0.011938 \t 283.250321 s\n","441 \t 14.372649 \t 7.190741 \t7.169643 \t 0.012265 \t 283.827977 s\n","442 \t 14.311550 \t 7.178327 \t7.117731 \t 0.015492 \t 284.459085 s\n","443 \t 14.278584 \t 7.149151 \t7.109323 \t 0.020110 \t 285.061763 s\n","444 \t 14.275997 \t 7.108142 \t7.152930 \t 0.014924 \t 285.720221 s\n","445 \t 14.268848 \t 7.159392 \t7.097773 \t 0.011683 \t 286.552613 s\n","446 \t 14.277113 \t 7.120846 \t7.140342 \t 0.015925 \t 287.061986 s\n","447 \t 14.501495 \t 7.281889 \t7.202727 \t 0.016880 \t 287.575118 s\n","448 \t 14.374902 \t 7.130651 \t7.227784 \t 0.016467 \t 288.073875 s\n","449 \t 14.385399 \t 7.156700 \t7.215923 \t 0.012776 \t 288.578252 s\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 162/162 [00:12<00:00, 13.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Link Prediction on Validation Set (Tri)\n","MRR: 0.3705\n","Hit@10: 0.5171\n","Hit@3: 0.3904\n","Hit@1: 0.2911\n","Link Prediction on Validation Set (All)\n","MRR: 0.3705\n","Hit@10: 0.5171\n","Hit@3: 0.3904\n","Hit@1: 0.2911\n","Relation Prediction on Validation Set (Tri)\n","MRR: 0.4044\n","Hit@10: 0.6358\n","Hit@3: 0.5062\n","Hit@1: 0.2469\n","Relation Prediction on Validation Set (All)\n","MRR: 0.4044\n","Hit@10: 0.6358\n","Hit@3: 0.5062\n","Hit@1: 0.2469\n","Numeric Value Prediction on Validation Set (Tri)\n","RMSE: 0.0587\n","Numeric Value Prediction on Validation Set (All)\n","RMSE: 0.0587\n","450 \t 14.204765 \t 7.063079 \t7.119827 \t 0.021860 \t 302.431434 s\n","451 \t 14.592737 \t 7.257229 \t7.307266 \t 0.028242 \t 302.957130 s\n","452 \t 14.717604 \t 7.394642 \t7.286833 \t 0.036128 \t 303.463541 s\n","453 \t 14.729185 \t 7.278107 \t7.423337 \t 0.027740 \t 304.107195 s\n","454 \t 14.595769 \t 7.245292 \t7.326273 \t 0.024204 \t 304.613718 s\n","455 \t 14.585075 \t 7.290813 \t7.244859 \t 0.049403 \t 305.122678 s\n","456 \t 14.481398 \t 7.243262 \t7.212829 \t 0.025308 \t 305.626407 s\n","457 \t 14.831724 \t 7.382060 \t7.430640 \t 0.019024 \t 306.136246 s\n","458 \t 14.671144 \t 7.211591 \t7.424562 \t 0.034991 \t 306.636881 s\n","459 \t 14.672468 \t 7.253248 \t7.383935 \t 0.035285 \t 307.153408 s\n","460 \t 14.497705 \t 7.338597 \t7.123755 \t 0.035353 \t 307.656873 s\n","461 \t 14.539509 \t 7.183911 \t7.320152 \t 0.035445 \t 308.299009 s\n","462 \t 14.655065 \t 7.354011 \t7.250896 \t 0.050158 \t 308.796712 s\n","463 \t 14.566704 \t 7.312151 \t7.222355 \t 0.032198 \t 309.307085 s\n","464 \t 14.704106 \t 7.270370 \t7.396806 \t 0.036930 \t 310.068264 s\n","465 \t 14.491143 \t 7.202799 \t7.238364 \t 0.049980 \t 311.300927 s\n","466 \t 14.458204 \t 7.187498 \t7.240978 \t 0.029728 \t 312.563175 s\n","467 \t 14.634984 \t 7.290152 \t7.292096 \t 0.052736 \t 313.559921 s\n","468 \t 14.662114 \t 7.281548 \t7.339427 \t 0.041140 \t 314.157854 s\n","469 \t 14.623181 \t 7.237751 \t7.328798 \t 0.056631 \t 314.767172 s\n","470 \t 14.571408 \t 7.293372 \t7.242458 \t 0.035579 \t 315.368210 s\n","471 \t 14.688269 \t 7.262446 \t7.398714 \t 0.027109 \t 316.166657 s\n","472 \t 14.785717 \t 7.439296 \t7.319614 \t 0.026806 \t 316.771908 s\n","473 \t 14.621330 \t 7.301151 \t7.297299 \t 0.022880 \t 317.375876 s\n","474 \t 14.409432 \t 7.137708 \t7.245877 \t 0.025847 \t 318.005765 s\n","475 \t 14.375982 \t 7.155094 \t7.200160 \t 0.020728 \t 318.647311 s\n","476 \t 14.519342 \t 7.296385 \t7.183925 \t 0.039033 \t 319.221631 s\n","477 \t 14.735118 \t 7.309363 \t7.379962 \t 0.045793 \t 319.737625 s\n","478 \t 14.566278 \t 7.196990 \t7.321093 \t 0.048194 \t 320.278811 s\n","479 \t 14.518440 \t 7.169261 \t7.298574 \t 0.050605 \t 320.844397 s\n","480 \t 14.514277 \t 7.206368 \t7.254994 \t 0.052915 \t 321.399726 s\n","481 \t 14.377832 \t 7.191064 \t7.118838 \t 0.067930 \t 322.069192 s\n","482 \t 14.667887 \t 7.282613 \t7.339242 \t 0.046031 \t 322.613533 s\n","483 \t 14.522582 \t 7.216969 \t7.253969 \t 0.051643 \t 323.168373 s\n","484 \t 14.638957 \t 7.273830 \t7.287372 \t 0.077754 \t 323.808248 s\n","485 \t 14.623548 \t 7.283368 \t7.294585 \t 0.045594 \t 324.447374 s\n","486 \t 14.339930 \t 7.078845 \t7.216154 \t 0.044932 \t 325.167653 s\n","487 \t 14.454950 \t 7.184816 \t7.234176 \t 0.035959 \t 325.817679 s\n","488 \t 14.512542 \t 7.233293 \t7.242156 \t 0.037094 \t 326.590435 s\n","489 \t 14.485414 \t 7.201536 \t7.219151 \t 0.064726 \t 327.275302 s\n","490 \t 14.651110 \t 7.327643 \t7.291286 \t 0.032180 \t 327.826437 s\n","491 \t 14.494273 \t 7.192303 \t7.237777 \t 0.064192 \t 328.363811 s\n","492 \t 14.603280 \t 7.231686 \t7.337762 \t 0.033831 \t 328.890130 s\n","493 \t 14.487705 \t 7.087757 \t7.360404 \t 0.039545 \t 329.420912 s\n","494 \t 14.243090 \t 7.043863 \t7.177901 \t 0.021326 \t 329.959791 s\n","495 \t 14.673573 \t 7.250472 \t7.379834 \t 0.043267 \t 330.526461 s\n","496 \t 14.456044 \t 7.151924 \t7.267345 \t 0.036775 \t 331.055863 s\n","497 \t 14.518530 \t 7.251319 \t7.229812 \t 0.037400 \t 331.575743 s\n","498 \t 14.217783 \t 7.063386 \t7.129506 \t 0.024892 \t 332.230537 s\n","499 \t 14.547008 \t 7.247311 \t7.246336 \t 0.053360 \t 332.745922 s\n","500 \t 14.367515 \t 7.091614 \t7.236537 \t 0.039363 \t 333.276726 s\n","501 \t 14.527192 \t 7.210800 \t7.292684 \t 0.023708 \t 333.787635 s\n","502 \t 14.525254 \t 7.228462 \t7.272786 \t 0.024006 \t 334.309064 s\n","503 \t 14.437278 \t 7.131553 \t7.265685 \t 0.040040 \t 334.817669 s\n","504 \t 14.505040 \t 7.130264 \t7.342884 \t 0.031892 \t 335.322148 s\n","505 \t 14.408513 \t 7.116431 \t7.262085 \t 0.029996 \t 335.825125 s\n","506 \t 14.435857 \t 7.180872 \t7.222662 \t 0.032322 \t 336.332697 s\n","507 \t 14.498914 \t 7.217957 \t7.233036 \t 0.047921 \t 336.909559 s\n","508 \t 14.336082 \t 7.161714 \t7.154560 \t 0.019809 \t 337.700187 s\n","509 \t 14.511742 \t 7.233201 \t7.240282 \t 0.038260 \t 338.305041 s\n","510 \t 14.583393 \t 7.225126 \t7.317843 \t 0.040423 \t 338.983701 s\n","511 \t 14.559125 \t 7.210892 \t7.315857 \t 0.032376 \t 339.649496 s\n","512 \t 14.377878 \t 7.101862 \t7.238172 \t 0.037844 \t 340.150529 s\n","513 \t 14.577239 \t 7.257478 \t7.294255 \t 0.025506 \t 340.672508 s\n","514 \t 14.491323 \t 7.213686 \t7.230763 \t 0.046873 \t 341.178545 s\n","515 \t 14.317052 \t 7.015136 \t7.242196 \t 0.059720 \t 341.697862 s\n","516 \t 14.445240 \t 7.184975 \t7.219582 \t 0.040682 \t 342.210640 s\n","517 \t 14.499430 \t 7.215365 \t7.228606 \t 0.055459 \t 342.732020 s\n","518 \t 14.480266 \t 7.145229 \t7.294955 \t 0.040083 \t 343.370367 s\n","519 \t 14.420357 \t 7.224961 \t7.149095 \t 0.046301 \t 343.882290 s\n","520 \t 14.399139 \t 7.205309 \t7.163553 \t 0.030277 \t 344.387354 s\n","521 \t 14.465364 \t 7.248237 \t7.171345 \t 0.045782 \t 344.899963 s\n","522 \t 14.474040 \t 7.171918 \t7.255721 \t 0.046401 \t 345.401529 s\n","523 \t 14.419600 \t 7.013139 \t7.381662 \t 0.024799 \t 345.922900 s\n","524 \t 14.409594 \t 7.244392 \t7.135532 \t 0.029669 \t 346.428314 s\n","525 \t 14.378325 \t 7.065998 \t7.289780 \t 0.022548 \t 346.937455 s\n","526 \t 14.449568 \t 7.249626 \t7.171983 \t 0.027959 \t 347.443524 s\n","527 \t 14.314806 \t 7.031580 \t7.249270 \t 0.033956 \t 347.958296 s\n","528 \t 14.522153 \t 7.196151 \t7.284137 \t 0.041865 \t 348.613234 s\n","529 \t 14.434311 \t 7.137648 \t7.264046 \t 0.032617 \t 349.132392 s\n","530 \t 14.505339 \t 7.255972 \t7.214984 \t 0.034382 \t 349.652517 s\n","531 \t 14.345360 \t 7.037943 \t7.277456 \t 0.029961 \t 350.323737 s\n","532 \t 14.503464 \t 7.167621 \t7.294506 \t 0.041337 \t 350.956723 s\n","533 \t 14.417892 \t 7.140396 \t7.246259 \t 0.031237 \t 351.599478 s\n","534 \t 14.388731 \t 7.091980 \t7.272643 \t 0.024108 \t 352.290664 s\n","535 \t 14.232419 \t 7.027088 \t7.164009 \t 0.041322 \t 352.911253 s\n","536 \t 14.301133 \t 7.052312 \t7.217100 \t 0.031721 \t 353.434591 s\n","537 \t 14.260834 \t 7.109710 \t7.111912 \t 0.039213 \t 354.084905 s\n","538 \t 14.331313 \t 7.082710 \t7.230697 \t 0.017907 \t 354.591829 s\n","539 \t 14.387448 \t 7.115971 \t7.204639 \t 0.066838 \t 355.105125 s\n","540 \t 14.216179 \t 7.068077 \t7.101655 \t 0.046446 \t 355.610462 s\n","541 \t 14.377311 \t 7.133235 \t7.214941 \t 0.029134 \t 356.161157 s\n","542 \t 14.406344 \t 7.152473 \t7.197711 \t 0.056160 \t 356.662210 s\n","543 \t 14.517107 \t 7.167487 \t7.318561 \t 0.031060 \t 357.177340 s\n","544 \t 14.245035 \t 7.064784 \t7.147777 \t 0.032474 \t 357.680020 s\n","545 \t 14.427143 \t 7.168190 \t7.226267 \t 0.032686 \t 358.337399 s\n","546 \t 14.398538 \t 7.213611 \t7.140581 \t 0.044346 \t 358.849492 s\n","547 \t 14.261046 \t 7.116784 \t7.100800 \t 0.043462 \t 359.369645 s\n","548 \t 14.303449 \t 7.090977 \t7.172331 \t 0.040141 \t 359.886228 s\n","549 \t 14.461438 \t 7.136585 \t7.280582 \t 0.044272 \t 360.407222 s\n","550 \t 14.300881 \t 7.171544 \t7.097071 \t 0.032267 \t 360.919213 s\n","551 \t 14.402768 \t 7.128443 \t7.238679 \t 0.035645 \t 361.457099 s\n","552 \t 14.456605 \t 7.226430 \t7.206794 \t 0.023381 \t 361.962965 s\n","553 \t 14.430311 \t 7.198103 \t7.194296 \t 0.037911 \t 362.474552 s\n","554 \t 14.424297 \t 7.107782 \t7.293629 \t 0.022886 \t 363.053262 s\n","555 \t 14.236660 \t 7.074181 \t7.133334 \t 0.029145 \t 363.832520 s\n","556 \t 14.297452 \t 7.047500 \t7.202549 \t 0.047403 \t 364.453373 s\n","557 \t 14.221835 \t 7.082788 \t7.109385 \t 0.029661 \t 365.089584 s\n","558 \t 14.320843 \t 7.113273 \t7.181267 \t 0.026302 \t 365.760375 s\n","559 \t 14.258523 \t 7.085835 \t7.143931 \t 0.028757 \t 366.263705 s\n","560 \t 14.591396 \t 7.161213 \t7.397566 \t 0.032617 \t 366.772902 s\n","561 \t 14.147070 \t 7.057974 \t7.065504 \t 0.023592 \t 367.277786 s\n","562 \t 14.331645 \t 7.020729 \t7.281733 \t 0.029183 \t 367.787235 s\n","563 \t 14.369322 \t 7.104668 \t7.237933 \t 0.026721 \t 368.294530 s\n","564 \t 14.297923 \t 7.128889 \t7.134952 \t 0.034082 \t 368.805758 s\n","565 \t 14.299897 \t 7.111069 \t7.170347 \t 0.018480 \t 369.451306 s\n","566 \t 14.066970 \t 6.993495 \t7.033515 \t 0.039959 \t 369.961319 s\n","567 \t 14.392542 \t 7.160520 \t7.211754 \t 0.020269 \t 370.460623 s\n","568 \t 14.201032 \t 7.038280 \t7.137589 \t 0.025163 \t 370.977592 s\n","569 \t 14.383457 \t 7.109951 \t7.252834 \t 0.020672 \t 371.480071 s\n","570 \t 14.247344 \t 7.121680 \t7.099755 \t 0.025909 \t 371.999458 s\n","571 \t 14.345653 \t 7.109970 \t7.205338 \t 0.030344 \t 372.505317 s\n","572 \t 14.407578 \t 7.102636 \t7.278346 \t 0.026597 \t 373.011043 s\n","573 \t 14.483158 \t 7.237654 \t7.216180 \t 0.029325 \t 373.648059 s\n","574 \t 14.204802 \t 7.043105 \t7.126662 \t 0.035035 \t 374.164222 s\n","575 \t 14.423665 \t 7.129282 \t7.223754 \t 0.070629 \t 374.664793 s\n","576 \t 14.332981 \t 7.106570 \t7.177857 \t 0.048554 \t 375.174447 s\n","577 \t 14.363127 \t 7.139075 \t7.176368 \t 0.047684 \t 375.674089 s\n","578 \t 14.374159 \t 7.134753 \t7.212716 \t 0.026690 \t 376.310404 s\n","579 \t 14.222897 \t 7.079980 \t7.097429 \t 0.045489 \t 376.915807 s\n","580 \t 14.302801 \t 7.073925 \t7.189392 \t 0.039484 \t 377.525640 s\n","581 \t 14.172344 \t 7.031906 \t7.093228 \t 0.047210 \t 378.175385 s\n","582 \t 14.341709 \t 7.133956 \t7.188720 \t 0.019033 \t 378.969509 s\n","583 \t 14.259809 \t 7.032204 \t7.187112 \t 0.040493 \t 379.500727 s\n","584 \t 14.186601 \t 7.041384 \t7.120613 \t 0.024604 \t 380.008835 s\n","585 \t 14.295078 \t 7.135018 \t7.133427 \t 0.026633 \t 380.525309 s\n","586 \t 14.138693 \t 6.985983 \t7.126692 \t 0.026019 \t 381.032380 s\n","587 \t 14.409966 \t 7.138314 \t7.236523 \t 0.035129 \t 381.553206 s\n","588 \t 14.366724 \t 7.121008 \t7.229360 \t 0.016357 \t 382.069274 s\n","589 \t 14.227381 \t 7.154826 \t7.052852 \t 0.019703 \t 382.588707 s\n","590 \t 14.299051 \t 7.124617 \t7.143182 \t 0.031253 \t 383.097333 s\n","591 \t 14.176468 \t 7.063784 \t7.091159 \t 0.021524 \t 383.618688 s\n","592 \t 14.193009 \t 7.108252 \t7.069106 \t 0.015651 \t 384.273778 s\n","593 \t 14.117417 \t 6.981752 \t7.121159 \t 0.014506 \t 384.776254 s\n","594 \t 14.117333 \t 6.956353 \t7.142000 \t 0.018979 \t 385.289194 s\n","595 \t 14.386593 \t 7.213820 \t7.139125 \t 0.033647 \t 385.792278 s\n","596 \t 14.127420 \t 7.075820 \t7.034193 \t 0.017407 \t 386.314721 s\n","597 \t 14.324870 \t 7.108284 \t7.174541 \t 0.042045 \t 386.817515 s\n","598 \t 14.279515 \t 7.122445 \t7.130545 \t 0.026525 \t 387.320453 s\n","599 \t 14.209739 \t 7.071708 \t7.117271 \t 0.020760 \t 387.822175 s\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 162/162 [00:12<00:00, 13.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Link Prediction on Validation Set (Tri)\n","MRR: 0.3570\n","Hit@10: 0.5240\n","Hit@3: 0.3870\n","Hit@1: 0.2671\n","Link Prediction on Validation Set (All)\n","MRR: 0.3570\n","Hit@10: 0.5240\n","Hit@3: 0.3870\n","Hit@1: 0.2671\n","Relation Prediction on Validation Set (Tri)\n","MRR: 0.3850\n","Hit@10: 0.6358\n","Hit@3: 0.4877\n","Hit@1: 0.2284\n","Relation Prediction on Validation Set (All)\n","MRR: 0.3850\n","Hit@10: 0.6358\n","Hit@3: 0.4877\n","Hit@1: 0.2284\n","Numeric Value Prediction on Validation Set (Tri)\n","RMSE: 0.0915\n","Numeric Value Prediction on Validation Set (All)\n","RMSE: 0.0915\n","600 \t 14.297311 \t 7.096192 \t7.186017 \t 0.015102 \t 401.667379 s\n","601 \t 14.122218 \t 7.011693 \t7.080981 \t 0.029544 \t 402.390174 s\n","602 \t 14.279458 \t 7.094407 \t7.146703 \t 0.038347 \t 403.018617 s\n","603 \t 14.312193 \t 7.122225 \t7.162662 \t 0.027306 \t 403.644735 s\n","604 \t 14.227939 \t 7.027842 \t7.152777 \t 0.047319 \t 404.281769 s\n","605 \t 14.169166 \t 6.996378 \t7.139646 \t 0.033142 \t 404.969026 s\n","606 \t 14.254121 \t 7.095445 \t7.132048 \t 0.026627 \t 405.514086 s\n","607 \t 14.247487 \t 6.977210 \t7.248944 \t 0.021333 \t 406.019657 s\n","608 \t 14.272386 \t 7.147240 \t7.100194 \t 0.024951 \t 406.529002 s\n","609 \t 14.224668 \t 6.984888 \t7.212700 \t 0.027080 \t 407.044094 s\n","610 \t 14.260955 \t 7.076745 \t7.159533 \t 0.024677 \t 407.557277 s\n","611 \t 14.197048 \t 7.066009 \t7.110567 \t 0.020472 \t 408.194788 s\n","612 \t 14.170458 \t 7.004148 \t7.138634 \t 0.027675 \t 408.710398 s\n","613 \t 14.310341 \t 7.131021 \t7.156088 \t 0.023232 \t 409.246755 s\n","614 \t 14.120263 \t 7.041162 \t7.048784 \t 0.030317 \t 409.895366 s\n","615 \t 14.110499 \t 7.008564 \t7.083451 \t 0.018484 \t 410.522801 s\n","616 \t 14.296887 \t 7.074093 \t7.202711 \t 0.020083 \t 411.129922 s\n","617 \t 14.323040 \t 7.076732 \t7.206654 \t 0.039654 \t 411.755681 s\n","618 \t 14.341861 \t 7.101279 \t7.216015 \t 0.024567 \t 412.362870 s\n","619 \t 14.324553 \t 7.113983 \t7.186244 \t 0.024326 \t 413.148449 s\n","620 \t 14.031132 \t 6.989863 \t7.011667 \t 0.029602 \t 413.789175 s\n","621 \t 14.221272 \t 7.072284 \t7.124573 \t 0.024415 \t 414.386302 s\n","622 \t 14.154917 \t 7.057822 \t7.066335 \t 0.030760 \t 415.016558 s\n","623 \t 14.331721 \t 7.091716 \t7.221467 \t 0.018538 \t 415.951923 s\n","624 \t 14.436003 \t 7.221407 \t7.199246 \t 0.015349 \t 417.161784 s\n","625 \t 14.217949 \t 7.059537 \t7.133735 \t 0.024678 \t 418.200667 s\n","626 \t 14.018026 \t 6.969101 \t7.027891 \t 0.021035 \t 418.982101 s\n","627 \t 14.175745 \t 7.048979 \t7.105089 \t 0.021677 \t 419.483180 s\n","628 \t 14.163162 \t 7.058039 \t7.091518 \t 0.013605 \t 420.024100 s\n","629 \t 14.287637 \t 7.121592 \t7.145647 \t 0.020398 \t 420.686488 s\n","630 \t 14.206286 \t 7.085319 \t7.100008 \t 0.020960 \t 421.229761 s\n","631 \t 14.116196 \t 7.028779 \t7.061184 \t 0.026234 \t 421.766651 s\n","632 \t 14.154218 \t 7.029546 \t7.095283 \t 0.029390 \t 422.334511 s\n","633 \t 14.112654 \t 6.940839 \t7.140229 \t 0.031587 \t 422.881432 s\n","634 \t 14.048334 \t 7.051304 \t6.958151 \t 0.038878 \t 423.439307 s\n","635 \t 14.303603 \t 7.125051 \t7.149633 \t 0.028919 \t 423.972834 s\n","636 \t 14.241852 \t 7.098245 \t7.099231 \t 0.044376 \t 424.509712 s\n","637 \t 14.306425 \t 7.095932 \t7.182965 \t 0.027528 \t 425.046923 s\n","638 \t 14.051808 \t 7.015706 \t7.008992 \t 0.027110 \t 425.596763 s\n","639 \t 14.397149 \t 7.068839 \t7.310487 \t 0.017824 \t 426.288235 s\n","640 \t 14.032430 \t 6.921840 \t7.084310 \t 0.026280 \t 426.803705 s\n","641 \t 14.075983 \t 7.009793 \t7.046313 \t 0.019877 \t 427.337603 s\n","642 \t 14.216749 \t 7.040036 \t7.152879 \t 0.023835 \t 427.882916 s\n","643 \t 14.201264 \t 7.052475 \t7.123508 \t 0.025281 \t 428.439582 s\n","644 \t 14.174212 \t 7.063244 \t7.087867 \t 0.023101 \t 428.996741 s\n","645 \t 14.278865 \t 7.094844 \t7.160388 \t 0.023633 \t 429.672970 s\n","646 \t 14.076323 \t 7.047204 \t7.012589 \t 0.016530 \t 430.382672 s\n","647 \t 14.120471 \t 7.069503 \t7.027883 \t 0.023084 \t 431.023875 s\n","648 \t 14.082291 \t 7.022228 \t7.048012 \t 0.012050 \t 431.706795 s\n","649 \t 14.030452 \t 6.987529 \t7.025599 \t 0.017325 \t 432.472281 s\n","650 \t 14.274393 \t 7.150948 \t7.106650 \t 0.016795 \t 432.971414 s\n","651 \t 14.248070 \t 7.032284 \t7.195895 \t 0.019891 \t 433.518683 s\n","652 \t 14.240430 \t 7.112618 \t7.104783 \t 0.023029 \t 434.029089 s\n","653 \t 14.126403 \t 7.078500 \t7.030858 \t 0.017046 \t 434.540371 s\n","654 \t 14.177464 \t 7.008362 \t7.150479 \t 0.018623 \t 435.043497 s\n","655 \t 14.270830 \t 7.053986 \t7.199318 \t 0.017526 \t 435.551552 s\n","656 \t 14.206947 \t 7.022849 \t7.170134 \t 0.013964 \t 436.051112 s\n","657 \t 14.069878 \t 6.989201 \t7.059133 \t 0.021544 \t 436.567097 s\n","658 \t 14.186838 \t 7.017833 \t7.141784 \t 0.027221 \t 437.213201 s\n","659 \t 14.053499 \t 7.054791 \t6.968199 \t 0.030509 \t 437.738109 s\n","660 \t 14.052079 \t 6.943864 \t7.084966 \t 0.023250 \t 438.250554 s\n","661 \t 13.892899 \t 6.876783 \t6.994033 \t 0.022082 \t 438.776498 s\n","662 \t 14.217864 \t 7.125735 \t7.065417 \t 0.026713 \t 439.281859 s\n","663 \t 14.068898 \t 7.056176 \t6.984167 \t 0.028555 \t 439.801463 s\n","664 \t 14.148472 \t 6.973843 \t7.148196 \t 0.026433 \t 440.313471 s\n","665 \t 14.232406 \t 7.116693 \t7.091361 \t 0.024352 \t 440.839468 s\n","666 \t 14.174877 \t 7.099645 \t7.055922 \t 0.019310 \t 441.475696 s\n","667 \t 14.220968 \t 7.094636 \t7.114518 \t 0.011813 \t 441.978404 s\n","668 \t 14.246823 \t 7.031462 \t7.198512 \t 0.016849 \t 442.580065 s\n","669 \t 14.220457 \t 7.075645 \t7.125283 \t 0.019529 \t 443.199270 s\n","670 \t 14.192953 \t 7.028376 \t7.144130 \t 0.020447 \t 443.820330 s\n","671 \t 13.988578 \t 6.929572 \t7.034817 \t 0.024189 \t 444.476741 s\n","672 \t 13.996270 \t 6.902658 \t7.081962 \t 0.011651 \t 445.139133 s\n","673 \t 14.198007 \t 7.085205 \t7.090567 \t 0.022235 \t 445.644160 s\n","674 \t 14.123869 \t 7.008559 \t7.103327 \t 0.011984 \t 446.149364 s\n","675 \t 14.125458 \t 7.063442 \t7.040462 \t 0.021555 \t 446.672867 s\n","676 \t 13.995508 \t 7.036141 \t6.939180 \t 0.020187 \t 447.322401 s\n","677 \t 14.068771 \t 7.006725 \t7.012901 \t 0.049144 \t 447.835163 s\n","678 \t 14.112532 \t 7.054306 \t7.044551 \t 0.013676 \t 448.344226 s\n","679 \t 14.145263 \t 6.955909 \t7.148487 \t 0.040868 \t 448.861655 s\n","680 \t 14.150690 \t 6.968613 \t7.160577 \t 0.021500 \t 449.372711 s\n","681 \t 14.037343 \t 7.001295 \t7.007167 \t 0.028882 \t 449.880643 s\n","682 \t 14.084018 \t 7.019860 \t7.047426 \t 0.016732 \t 450.394751 s\n","683 \t 13.930319 \t 6.921559 \t6.986944 \t 0.021816 \t 450.903479 s\n","684 \t 14.074821 \t 6.966866 \t7.091864 \t 0.016091 \t 451.427831 s\n","685 \t 14.299166 \t 7.129725 \t7.151186 \t 0.018256 \t 451.932052 s\n","686 \t 14.041373 \t 6.929911 \t7.091997 \t 0.019466 \t 452.575673 s\n","687 \t 14.324162 \t 7.068884 \t7.245372 \t 0.009906 \t 453.083609 s\n","688 \t 14.084871 \t 7.092637 \t6.977661 \t 0.014574 \t 453.599741 s\n","689 \t 13.990035 \t 7.010278 \t6.965794 \t 0.013963 \t 454.099160 s\n","690 \t 14.043585 \t 7.005636 \t7.022318 \t 0.015631 \t 454.618893 s\n","691 \t 14.100361 \t 7.071399 \t7.016678 \t 0.012283 \t 455.139579 s\n","692 \t 14.050469 \t 6.959273 \t7.071191 \t 0.020006 \t 455.794607 s\n","693 \t 14.203046 \t 7.084976 \t7.102036 \t 0.016034 \t 456.456339 s\n","694 \t 14.042787 \t 7.010214 \t7.005632 \t 0.026940 \t 457.239649 s\n","695 \t 14.180421 \t 7.004279 \t7.158039 \t 0.018103 \t 457.946212 s\n","696 \t 14.070216 \t 6.951081 \t7.092518 \t 0.026616 \t 458.477282 s\n","697 \t 14.185894 \t 7.034946 \t7.128856 \t 0.022091 \t 458.985192 s\n","698 \t 14.165985 \t 7.046355 \t7.103166 \t 0.016464 \t 459.496024 s\n","699 \t 14.157449 \t 6.985797 \t7.152746 \t 0.018906 \t 460.000168 s\n","700 \t 14.046980 \t 6.904353 \t7.125515 \t 0.017112 \t 460.515661 s\n","701 \t 14.034173 \t 6.988693 \t7.034069 \t 0.011412 \t 461.020589 s\n","702 \t 14.092780 \t 6.985837 \t7.091394 \t 0.015549 \t 461.526413 s\n","703 \t 14.135155 \t 6.996492 \t7.121012 \t 0.017651 \t 462.164260 s\n","704 \t 14.208617 \t 7.076751 \t7.107977 \t 0.023890 \t 462.689582 s\n","705 \t 14.087260 \t 7.020095 \t7.039422 \t 0.027743 \t 463.195829 s\n","706 \t 13.993804 \t 6.990033 \t6.994270 \t 0.009500 \t 463.715727 s\n","707 \t 14.012475 \t 6.977692 \t7.022940 \t 0.011843 \t 464.219817 s\n","708 \t 14.127066 \t 6.957399 \t7.156205 \t 0.013462 \t 464.736185 s\n","709 \t 14.204834 \t 7.089627 \t7.104584 \t 0.010623 \t 465.241644 s\n","710 \t 13.986372 \t 6.920443 \t7.038754 \t 0.027176 \t 465.756597 s\n","711 \t 14.232440 \t 7.013968 \t7.204768 \t 0.013703 \t 466.263168 s\n","712 \t 14.148997 \t 7.135204 \t6.995374 \t 0.018419 \t 466.784456 s\n","713 \t 13.939237 \t 6.954864 \t6.965649 \t 0.018724 \t 467.429463 s\n","714 \t 14.144674 \t 7.046109 \t7.082854 \t 0.015711 \t 467.933131 s\n","715 \t 14.069037 \t 6.983105 \t7.071437 \t 0.014495 \t 468.543664 s\n","716 \t 14.255170 \t 7.038216 \t7.203772 \t 0.013183 \t 469.160006 s\n","717 \t 14.226559 \t 7.086951 \t7.127739 \t 0.011870 \t 469.760659 s\n","718 \t 14.244280 \t 7.140233 \t7.083275 \t 0.020771 \t 470.445333 s\n","719 \t 14.045985 \t 6.925001 \t7.111724 \t 0.009260 \t 471.105262 s\n","720 \t 14.009736 \t 6.918375 \t7.067472 \t 0.023889 \t 471.605215 s\n","721 \t 14.038720 \t 6.988473 \t7.030332 \t 0.019915 \t 472.118891 s\n","722 \t 14.200926 \t 7.105256 \t7.077742 \t 0.017927 \t 472.616569 s\n","723 \t 14.063086 \t 6.955044 \t7.086152 \t 0.021890 \t 473.246665 s\n","724 \t 14.156565 \t 7.110734 \t7.032110 \t 0.013721 \t 473.750132 s\n","725 \t 13.961300 \t 6.943604 \t6.997451 \t 0.020245 \t 474.261207 s\n","726 \t 13.936779 \t 6.866889 \t7.037986 \t 0.031903 \t 474.767718 s\n","727 \t 14.051857 \t 7.036825 \t6.991154 \t 0.023879 \t 475.277152 s\n","728 \t 13.960890 \t 6.900126 \t7.046321 \t 0.014444 \t 475.776859 s\n","729 \t 14.022494 \t 7.077900 \t6.919757 \t 0.024837 \t 476.288933 s\n","730 \t 14.144613 \t 7.073123 \t7.047599 \t 0.023890 \t 476.788266 s\n","731 \t 14.023923 \t 6.929075 \t7.067032 \t 0.027816 \t 477.453467 s\n","732 \t 14.113434 \t 6.966004 \t7.127210 \t 0.020220 \t 477.959738 s\n","733 \t 13.964571 \t 6.961283 \t6.991393 \t 0.011895 \t 478.469620 s\n","734 \t 14.215880 \t 7.058332 \t7.140447 \t 0.017101 \t 478.984353 s\n","735 \t 14.001777 \t 6.985091 \t7.003063 \t 0.013624 \t 479.496133 s\n","736 \t 14.135940 \t 7.084645 \t7.034751 \t 0.016544 \t 480.001021 s\n","737 \t 13.998176 \t 6.967143 \t7.019032 \t 0.012001 \t 480.509273 s\n","738 \t 14.151505 \t 7.033485 \t7.099703 \t 0.018316 \t 481.030490 s\n","739 \t 13.992662 \t 6.918028 \t7.059884 \t 0.014751 \t 481.681351 s\n","740 \t 13.866162 \t 6.946414 \t6.901579 \t 0.018169 \t 482.477535 s\n","741 \t 13.964749 \t 6.970293 \t6.982967 \t 0.011489 \t 483.079646 s\n","742 \t 14.038118 \t 6.939117 \t7.082020 \t 0.016981 \t 483.743416 s\n","743 \t 14.063183 \t 7.022014 \t7.022920 \t 0.018249 \t 484.354154 s\n","744 \t 14.030223 \t 6.966016 \t7.046651 \t 0.017556 \t 484.878406 s\n","745 \t 14.027264 \t 6.930318 \t7.072805 \t 0.024140 \t 485.391491 s\n","746 \t 14.032436 \t 7.019748 \t6.998255 \t 0.014433 \t 485.929883 s\n","747 \t 14.029890 \t 6.926733 \t7.083022 \t 0.020134 \t 486.443617 s\n","748 \t 14.121171 \t 7.040949 \t7.069152 \t 0.011070 \t 486.982933 s\n","749 \t 13.982417 \t 6.942515 \t7.022548 \t 0.017353 \t 487.490798 s\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 162/162 [00:12<00:00, 12.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Link Prediction on Validation Set (Tri)\n","MRR: 0.3483\n","Hit@10: 0.5137\n","Hit@3: 0.3836\n","Hit@1: 0.2637\n","Link Prediction on Validation Set (All)\n","MRR: 0.3483\n","Hit@10: 0.5137\n","Hit@3: 0.3836\n","Hit@1: 0.2637\n","Relation Prediction on Validation Set (Tri)\n","MRR: 0.3595\n","Hit@10: 0.6420\n","Hit@3: 0.4691\n","Hit@1: 0.1914\n","Relation Prediction on Validation Set (All)\n","MRR: 0.3595\n","Hit@10: 0.6420\n","Hit@3: 0.4691\n","Hit@1: 0.1914\n","Numeric Value Prediction on Validation Set (Tri)\n","RMSE: 0.0787\n","Numeric Value Prediction on Validation Set (All)\n","RMSE: 0.0787\n","750 \t 13.947024 \t 7.002151 \t6.915806 \t 0.029067 \t 501.759455 s\n","751 \t 14.005828 \t 6.943135 \t7.052449 \t 0.010243 \t 502.276602 s\n","752 \t 13.993050 \t 6.956317 \t7.011144 \t 0.025589 \t 502.788855 s\n","753 \t 14.115128 \t 7.013380 \t7.083155 \t 0.018592 \t 503.305916 s\n","754 \t 13.970355 \t 6.924316 \t7.025772 \t 0.020267 \t 503.815676 s\n","755 \t 14.190269 \t 7.064615 \t7.106934 \t 0.018720 \t 504.318611 s\n","756 \t 14.208289 \t 7.071441 \t7.117889 \t 0.018959 \t 504.841502 s\n","757 \t 13.979803 \t 7.007121 \t6.945259 \t 0.027423 \t 505.358880 s\n","758 \t 13.942044 \t 6.964991 \t6.962828 \t 0.014225 \t 505.865154 s\n","759 \t 13.900010 \t 6.834574 \t7.051116 \t 0.014319 \t 506.377620 s\n","760 \t 14.098023 \t 6.986849 \t7.095874 \t 0.015300 \t 507.022676 s\n","761 \t 14.004761 \t 6.941237 \t7.045680 \t 0.017844 \t 507.629779 s\n","762 \t 14.014215 \t 6.951335 \t7.049129 \t 0.013751 \t 508.253702 s\n","763 \t 14.067506 \t 7.029548 \t7.016907 \t 0.021051 \t 508.965726 s\n","764 \t 14.014856 \t 6.960871 \t7.037510 \t 0.016474 \t 510.020472 s\n","765 \t 14.137067 \t 7.024643 \t7.095011 \t 0.017413 \t 511.075220 s\n","766 \t 14.107028 \t 7.029386 \t7.064948 \t 0.012695 \t 511.700202 s\n","767 \t 13.998721 \t 6.898903 \t7.081437 \t 0.018381 \t 512.312517 s\n","768 \t 14.008437 \t 6.989099 \t7.010936 \t 0.008403 \t 512.943256 s\n","769 \t 13.960074 \t 6.968603 \t6.977137 \t 0.014335 \t 513.558020 s\n","770 \t 14.055748 \t 6.957324 \t7.085467 \t 0.012958 \t 514.368886 s\n","771 \t 14.022859 \t 6.980338 \t7.025498 \t 0.017022 \t 515.004636 s\n","772 \t 13.908075 \t 6.933807 \t6.955929 \t 0.018339 \t 515.614436 s\n","773 \t 13.973366 \t 7.009320 \t6.954532 \t 0.009514 \t 516.239507 s\n","774 \t 14.091001 \t 6.943951 \t7.129969 \t 0.017081 \t 516.856174 s\n","775 \t 14.001162 \t 7.053906 \t6.936954 \t 0.010302 \t 517.488665 s\n","776 \t 13.931197 \t 6.972918 \t6.946127 \t 0.012153 \t 518.074975 s\n","777 \t 13.954841 \t 6.958586 \t6.983419 \t 0.012836 \t 518.590489 s\n","778 \t 13.968294 \t 6.937574 \t7.015993 \t 0.014727 \t 519.254961 s\n","779 \t 14.029863 \t 6.946895 \t7.059536 \t 0.023432 \t 519.771800 s\n","780 \t 13.958433 \t 6.969980 \t6.976761 \t 0.011693 \t 520.310245 s\n","781 \t 13.862247 \t 6.918773 \t6.929527 \t 0.013947 \t 520.865536 s\n","782 \t 13.999181 \t 6.959786 \t7.025861 \t 0.013534 \t 521.552357 s\n","783 \t 14.002758 \t 6.989123 \t6.998057 \t 0.015579 \t 522.221132 s\n","784 \t 13.989035 \t 6.958032 \t7.018437 \t 0.012567 \t 522.909561 s\n","785 \t 13.913506 \t 6.926874 \t6.970070 \t 0.016561 \t 523.615168 s\n","786 \t 13.832502 \t 6.926676 \t6.888252 \t 0.017573 \t 524.277757 s\n","787 \t 13.886672 \t 6.893563 \t6.970039 \t 0.023071 \t 524.955868 s\n","788 \t 13.942746 \t 6.905206 \t7.025978 \t 0.011562 \t 525.499125 s\n","789 \t 13.787380 \t 6.856061 \t6.916325 \t 0.014994 \t 526.036175 s\n","790 \t 13.954196 \t 6.942109 \t6.993552 \t 0.018535 \t 526.559265 s\n","791 \t 14.045083 \t 7.017898 \t7.009684 \t 0.017501 \t 527.079253 s\n","792 \t 13.842280 \t 6.906080 \t6.922388 \t 0.013812 \t 527.594906 s\n","793 \t 14.029148 \t 7.005721 \t7.007121 \t 0.016306 \t 528.119339 s\n","794 \t 14.043166 \t 7.001925 \t7.026713 \t 0.014528 \t 528.679885 s\n","795 \t 14.050090 \t 6.970040 \t7.061906 \t 0.018143 \t 529.222295 s\n","796 \t 13.933568 \t 6.975572 \t6.941453 \t 0.016543 \t 529.749251 s\n","797 \t 13.901474 \t 6.864029 \t7.026864 \t 0.010582 \t 530.402762 s\n","798 \t 13.836671 \t 6.887206 \t6.934030 \t 0.015435 \t 530.927790 s\n","799 \t 14.006531 \t 6.968952 \t7.023276 \t 0.014303 \t 531.446069 s\n","800 \t 13.835754 \t 6.931442 \t6.889386 \t 0.014926 \t 531.974544 s\n","801 \t 13.809587 \t 6.903957 \t6.891082 \t 0.014548 \t 532.490794 s\n","802 \t 13.950865 \t 6.999847 \t6.935230 \t 0.015787 \t 533.022173 s\n","803 \t 13.873764 \t 6.913883 \t6.939801 \t 0.020081 \t 533.524683 s\n","804 \t 14.012164 \t 6.945878 \t7.045451 \t 0.020835 \t 534.070567 s\n","805 \t 13.962883 \t 7.038835 \t6.912329 \t 0.011720 \t 534.733394 s\n","806 \t 13.905878 \t 6.942307 \t6.947151 \t 0.016419 \t 535.353431 s\n","807 \t 13.850456 \t 6.919204 \t6.921381 \t 0.009871 \t 536.175655 s\n","808 \t 13.940695 \t 6.903061 \t7.021508 \t 0.016126 \t 536.879493 s\n","809 \t 14.107575 \t 7.077275 \t7.016816 \t 0.013485 \t 537.433780 s\n","810 \t 14.002231 \t 6.988426 \t6.990396 \t 0.023409 \t 537.962160 s\n","811 \t 13.998079 \t 6.923855 \t7.062027 \t 0.012197 \t 538.485833 s\n","812 \t 13.965123 \t 6.968412 \t6.985735 \t 0.010976 \t 538.999169 s\n","813 \t 13.807003 \t 6.899044 \t6.900271 \t 0.007688 \t 539.509806 s\n","814 \t 14.009902 \t 6.967658 \t7.031029 \t 0.011215 \t 540.029711 s\n","815 \t 13.911058 \t 6.964962 \t6.936661 \t 0.009436 \t 540.545398 s\n","816 \t 14.055892 \t 6.964284 \t7.081986 \t 0.009622 \t 541.056139 s\n","817 \t 13.958661 \t 6.886181 \t7.058515 \t 0.013965 \t 541.692235 s\n","818 \t 14.053070 \t 6.981197 \t7.057445 \t 0.014427 \t 542.206293 s\n","819 \t 14.034828 \t 6.927084 \t7.096596 \t 0.011148 \t 542.707084 s\n","820 \t 13.863879 \t 6.876686 \t6.972642 \t 0.014550 \t 543.219066 s\n","821 \t 13.945245 \t 6.963177 \t6.969326 \t 0.012741 \t 543.719972 s\n","822 \t 13.903739 \t 6.892492 \t7.002887 \t 0.008361 \t 544.242885 s\n","823 \t 13.862149 \t 6.864425 \t6.985498 \t 0.012226 \t 544.747684 s\n","824 \t 13.925323 \t 6.909672 \t7.005988 \t 0.009663 \t 545.259999 s\n","825 \t 13.890957 \t 6.935317 \t6.943109 \t 0.012531 \t 545.897969 s\n","826 \t 14.047579 \t 6.998276 \t7.038407 \t 0.010897 \t 546.414932 s\n","827 \t 13.965841 \t 6.985629 \t6.967955 \t 0.012257 \t 546.932527 s\n","828 \t 14.008436 \t 6.956559 \t7.039357 \t 0.012520 \t 547.557024 s\n","829 \t 13.781025 \t 6.819029 \t6.952846 \t 0.009150 \t 548.179561 s\n","830 \t 13.868549 \t 6.834873 \t7.021238 \t 0.012439 \t 548.791051 s\n","831 \t 13.974060 \t 6.898245 \t7.059173 \t 0.016641 \t 549.456239 s\n","832 \t 13.942665 \t 6.962789 \t6.965595 \t 0.014281 \t 550.101337 s\n","833 \t 14.067781 \t 6.977556 \t7.083519 \t 0.006706 \t 550.619070 s\n","834 \t 14.034472 \t 6.970643 \t7.053822 \t 0.010008 \t 551.275556 s\n","835 \t 13.898297 \t 6.898743 \t6.988424 \t 0.011131 \t 551.789652 s\n","836 \t 14.204677 \t 7.146264 \t7.050808 \t 0.007606 \t 552.308475 s\n","837 \t 13.870404 \t 6.929411 \t6.934044 \t 0.006948 \t 552.828221 s\n","838 \t 13.986762 \t 6.913735 \t7.062203 \t 0.010824 \t 553.331712 s\n","839 \t 13.929287 \t 6.899892 \t7.018324 \t 0.011071 \t 553.869209 s\n","840 \t 13.881694 \t 6.896476 \t6.971371 \t 0.013847 \t 554.375319 s\n","841 \t 13.835299 \t 6.850843 \t6.966790 \t 0.017666 \t 554.893443 s\n","842 \t 13.884647 \t 6.875051 \t7.000630 \t 0.008966 \t 555.391457 s\n","843 \t 13.943075 \t 6.972504 \t6.961678 \t 0.008894 \t 555.917793 s\n","844 \t 13.950625 \t 6.888827 \t7.053732 \t 0.008065 \t 556.563928 s\n","845 \t 14.026533 \t 6.988531 \t7.019990 \t 0.018013 \t 557.067645 s\n","846 \t 13.893025 \t 6.915182 \t6.960098 \t 0.017745 \t 557.582386 s\n","847 \t 13.861548 \t 6.864748 \t6.987180 \t 0.009619 \t 558.082680 s\n","848 \t 13.898124 \t 6.866822 \t7.021658 \t 0.009644 \t 558.592803 s\n","849 \t 13.921373 \t 6.979383 \t6.928818 \t 0.013172 \t 559.097079 s\n","850 \t 13.968038 \t 6.949464 \t7.004680 \t 0.013894 \t 559.605904 s\n","851 \t 13.948290 \t 6.926278 \t7.009861 \t 0.012152 \t 560.130272 s\n","852 \t 14.018289 \t 7.017287 \t6.990349 \t 0.010653 \t 560.769883 s\n","853 \t 13.984935 \t 7.034225 \t6.938408 \t 0.012303 \t 561.379454 s\n","854 \t 13.816858 \t 6.852323 \t6.957288 \t 0.007247 \t 562.181422 s\n","855 \t 13.973857 \t 6.874862 \t7.083911 \t 0.015083 \t 562.876198 s\n","856 \t 13.845463 \t 6.826701 \t7.007142 \t 0.011620 \t 563.458491 s\n","857 \t 14.113246 \t 7.092408 \t7.007948 \t 0.012891 \t 563.983652 s\n","858 \t 13.900450 \t 6.815096 \t7.071475 \t 0.013879 \t 564.480170 s\n","859 \t 13.930979 \t 6.999298 \t6.922588 \t 0.009093 \t 564.991917 s\n","860 \t 13.735005 \t 6.792412 \t6.933014 \t 0.009579 \t 565.489329 s\n","861 \t 14.037054 \t 6.941233 \t7.080442 \t 0.015379 \t 566.006836 s\n","862 \t 13.876981 \t 6.903587 \t6.964497 \t 0.008897 \t 566.503839 s\n","863 \t 13.910846 \t 6.883205 \t7.019876 \t 0.007764 \t 567.022136 s\n","864 \t 13.708863 \t 6.785677 \t6.915908 \t 0.007279 \t 567.650694 s\n","865 \t 13.958595 \t 6.935200 \t7.012331 \t 0.011064 \t 568.157260 s\n","866 \t 14.000462 \t 6.926181 \t7.062291 \t 0.011990 \t 568.682144 s\n","867 \t 13.895179 \t 6.878586 \t7.006720 \t 0.009873 \t 569.199378 s\n","868 \t 13.950111 \t 6.924453 \t7.016016 \t 0.009643 \t 569.703643 s\n","869 \t 13.851119 \t 6.853516 \t6.987259 \t 0.010344 \t 570.212589 s\n","870 \t 14.004905 \t 6.994029 \t7.002257 \t 0.008619 \t 570.709370 s\n","871 \t 14.012324 \t 6.913774 \t7.088771 \t 0.009779 \t 571.227755 s\n","872 \t 13.951838 \t 6.977983 \t6.964051 \t 0.009804 \t 571.859230 s\n","873 \t 13.877284 \t 6.796671 \t7.067617 \t 0.012995 \t 572.360173 s\n","874 \t 13.856852 \t 6.884010 \t6.961170 \t 0.011672 \t 572.859131 s\n","875 \t 13.990352 \t 6.942686 \t7.036154 \t 0.011512 \t 573.440341 s\n","876 \t 13.925357 \t 6.888812 \t7.024368 \t 0.012177 \t 574.059799 s\n","877 \t 13.850685 \t 6.925439 \t6.916944 \t 0.008302 \t 574.681515 s\n","878 \t 13.753039 \t 6.844142 \t6.900408 \t 0.008489 \t 575.331701 s\n","879 \t 13.993181 \t 6.961549 \t7.021356 \t 0.010276 \t 576.026131 s\n","880 \t 13.924080 \t 6.953006 \t6.961337 \t 0.009737 \t 576.533762 s\n","881 \t 13.961423 \t 6.976719 \t6.974955 \t 0.009749 \t 577.183820 s\n","882 \t 13.997517 \t 6.956647 \t7.030307 \t 0.010564 \t 577.709222 s\n","883 \t 13.841616 \t 6.878854 \t6.952037 \t 0.010725 \t 578.218387 s\n","884 \t 13.829920 \t 6.929138 \t6.894545 \t 0.006237 \t 578.738031 s\n","885 \t 13.839939 \t 6.931057 \t6.902797 \t 0.006084 \t 579.248421 s\n","886 \t 13.999896 \t 6.994470 \t6.999326 \t 0.006099 \t 579.771168 s\n","887 \t 13.983167 \t 6.910515 \t7.065078 \t 0.007573 \t 580.280864 s\n","888 \t 13.854528 \t 6.872498 \t6.973324 \t 0.008706 \t 580.810606 s\n","889 \t 13.781841 \t 6.937539 \t6.834917 \t 0.009385 \t 581.311170 s\n","890 \t 13.983543 \t 6.914737 \t7.061146 \t 0.007661 \t 581.833191 s\n","891 \t 13.960277 \t 7.012290 \t6.940367 \t 0.007619 \t 582.468765 s\n","892 \t 13.972921 \t 6.895905 \t7.069100 \t 0.007916 \t 582.974786 s\n","893 \t 13.956150 \t 6.942676 \t7.004460 \t 0.009014 \t 583.468474 s\n","894 \t 13.862910 \t 6.881588 \t6.975557 \t 0.005764 \t 583.983431 s\n","895 \t 13.858963 \t 6.861326 \t6.987607 \t 0.010029 \t 584.477592 s\n","896 \t 13.948711 \t 6.922434 \t7.015909 \t 0.010368 \t 584.992872 s\n","897 \t 13.902156 \t 6.870279 \t7.024550 \t 0.007326 \t 585.499398 s\n","898 \t 13.841783 \t 6.816495 \t7.019491 \t 0.005797 \t 586.017210 s\n","899 \t 13.745478 \t 6.873944 \t6.865350 \t 0.006185 \t 586.672715 s\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 162/162 [00:12<00:00, 13.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Link Prediction on Validation Set (Tri)\n","MRR: 0.3484\n","Hit@10: 0.4966\n","Hit@3: 0.3733\n","Hit@1: 0.2637\n","Link Prediction on Validation Set (All)\n","MRR: 0.3484\n","Hit@10: 0.4966\n","Hit@3: 0.3733\n","Hit@1: 0.2637\n","Relation Prediction on Validation Set (Tri)\n","MRR: 0.3680\n","Hit@10: 0.5988\n","Hit@3: 0.5247\n","Hit@1: 0.1914\n","Relation Prediction on Validation Set (All)\n","MRR: 0.3680\n","Hit@10: 0.5988\n","Hit@3: 0.5247\n","Hit@1: 0.1914\n","Numeric Value Prediction on Validation Set (Tri)\n","RMSE: 0.0578\n","Numeric Value Prediction on Validation Set (All)\n","RMSE: 0.0578\n","900 \t 13.907110 \t 6.880953 \t7.007442 \t 0.018715 \t 600.800142 s\n","901 \t 14.055840 \t 6.991822 \t7.056195 \t 0.007823 \t 601.452965 s\n","902 \t 13.928975 \t 6.915320 \t7.004024 \t 0.009631 \t 602.110858 s\n","903 \t 13.912425 \t 6.938043 \t6.960918 \t 0.013465 \t 602.734510 s\n","904 \t 13.882990 \t 6.871464 \t7.002522 \t 0.009004 \t 603.243129 s\n","905 \t 13.801983 \t 6.876338 \t6.920312 \t 0.005333 \t 603.756421 s\n","906 \t 13.777103 \t 6.808666 \t6.958584 \t 0.009854 \t 604.281672 s\n","907 \t 13.924639 \t 6.858865 \t7.053884 \t 0.011890 \t 604.794858 s\n","908 \t 13.926869 \t 6.925373 \t6.993732 \t 0.007764 \t 605.303699 s\n","909 \t 13.841434 \t 6.907189 \t6.924573 \t 0.009671 \t 605.953204 s\n","910 \t 13.728280 \t 6.825295 \t6.889652 \t 0.013332 \t 606.457546 s\n","911 \t 13.934392 \t 6.955426 \t6.968661 \t 0.010305 \t 606.976833 s\n","912 \t 14.077056 \t 6.983846 \t7.084774 \t 0.008436 \t 607.482945 s\n","913 \t 13.799813 \t 6.885036 \t6.907984 \t 0.006793 \t 607.997129 s\n","914 \t 13.862030 \t 6.858193 \t6.991773 \t 0.012064 \t 608.508429 s\n","915 \t 13.698125 \t 6.726958 \t6.961481 \t 0.009687 \t 609.030131 s\n","916 \t 13.809608 \t 6.847375 \t6.954490 \t 0.007743 \t 609.553361 s\n","917 \t 13.743859 \t 6.856229 \t6.880221 \t 0.007409 \t 610.294348 s\n","918 \t 13.893244 \t 6.883999 \t7.001945 \t 0.007300 \t 610.952641 s\n","919 \t 13.907667 \t 6.940769 \t6.957426 \t 0.009471 \t 611.562773 s\n","920 \t 13.824521 \t 6.892684 \t6.924608 \t 0.007229 \t 612.187363 s\n","921 \t 13.715545 \t 6.764991 \t6.941509 \t 0.009045 \t 613.004813 s\n","922 \t 13.987884 \t 6.930927 \t7.050053 \t 0.006904 \t 613.986052 s\n","923 \t 13.660482 \t 6.801892 \t6.849322 \t 0.009269 \t 615.066597 s\n","924 \t 13.880269 \t 6.893414 \t6.976279 \t 0.010575 \t 616.174047 s\n","925 \t 13.825763 \t 6.879701 \t6.934728 \t 0.011334 \t 616.900151 s\n","926 \t 13.847254 \t 6.887964 \t6.950105 \t 0.009185 \t 617.517452 s\n","927 \t 13.943225 \t 6.962413 \t6.973524 \t 0.007289 \t 618.328369 s\n","928 \t 13.745428 \t 6.877750 \t6.859010 \t 0.008667 \t 618.937827 s\n","929 \t 13.789218 \t 6.899157 \t6.883334 \t 0.006727 \t 619.564164 s\n","930 \t 13.822046 \t 6.915172 \t6.898527 \t 0.008348 \t 620.074984 s\n","931 \t 13.927543 \t 6.908786 \t7.008437 \t 0.010320 \t 620.610711 s\n","932 \t 13.851138 \t 6.904212 \t6.940029 \t 0.006897 \t 621.134470 s\n","933 \t 13.813371 \t 6.939002 \t6.867547 \t 0.006823 \t 621.662458 s\n","934 \t 13.955523 \t 6.927071 \t7.021857 \t 0.006595 \t 622.180708 s\n","935 \t 13.830266 \t 6.890591 \t6.933783 \t 0.005893 \t 622.711144 s\n","936 \t 13.888556 \t 6.871851 \t7.007394 \t 0.009312 \t 623.240782 s\n","937 \t 13.893352 \t 6.889404 \t6.998214 \t 0.005733 \t 623.917225 s\n","938 \t 13.710552 \t 6.889569 \t6.812266 \t 0.008717 \t 624.460892 s\n","939 \t 13.874390 \t 6.866079 \t7.001588 \t 0.006723 \t 624.991144 s\n","940 \t 13.925853 \t 7.004425 \t6.913578 \t 0.007850 \t 625.523470 s\n","941 \t 13.855109 \t 6.894927 \t6.952857 \t 0.007326 \t 626.072567 s\n","942 \t 13.909998 \t 6.961865 \t6.941953 \t 0.006180 \t 626.680007 s\n","943 \t 13.784640 \t 6.876574 \t6.899799 \t 0.008268 \t 627.358960 s\n","944 \t 13.827522 \t 6.935142 \t6.881702 \t 0.010679 \t 628.014699 s\n","945 \t 13.848395 \t 6.881117 \t6.959116 \t 0.008163 \t 628.876659 s\n","946 \t 13.935199 \t 6.944736 \t6.980557 \t 0.009905 \t 629.603885 s\n","947 \t 13.867346 \t 6.856927 \t7.001055 \t 0.009364 \t 630.149476 s\n","948 \t 13.882614 \t 6.859928 \t7.017041 \t 0.005645 \t 630.678411 s\n","949 \t 13.739218 \t 6.799492 \t6.934371 \t 0.005355 \t 631.244746 s\n","950 \t 13.936974 \t 6.977932 \t6.948874 \t 0.010167 \t 631.793112 s\n","951 \t 13.787916 \t 6.875944 \t6.906104 \t 0.005868 \t 632.334978 s\n","952 \t 13.872071 \t 6.878500 \t6.983932 \t 0.009639 \t 632.870297 s\n","953 \t 13.854344 \t 6.871574 \t6.976927 \t 0.005843 \t 633.387295 s\n","954 \t 13.641392 \t 6.821235 \t6.812219 \t 0.007937 \t 634.027693 s\n","955 \t 13.912821 \t 6.955224 \t6.947730 \t 0.009868 \t 634.529827 s\n","956 \t 13.967391 \t 7.003899 \t6.953312 \t 0.010180 \t 635.042495 s\n","957 \t 13.793448 \t 6.854006 \t6.931430 \t 0.008012 \t 635.547800 s\n","958 \t 13.908856 \t 6.799694 \t7.102128 \t 0.007034 \t 636.062354 s\n","959 \t 13.799609 \t 6.768167 \t7.025478 \t 0.005965 \t 636.582781 s\n","960 \t 13.994126 \t 6.975838 \t7.011575 \t 0.006712 \t 637.088700 s\n","961 \t 13.812986 \t 6.924658 \t6.878302 \t 0.010025 \t 637.596608 s\n","962 \t 13.839433 \t 6.896991 \t6.934937 \t 0.007504 \t 638.115729 s\n","963 \t 13.780812 \t 6.835816 \t6.933984 \t 0.011013 \t 638.619699 s\n","964 \t 13.695821 \t 6.807255 \t6.882061 \t 0.006506 \t 639.266029 s\n","965 \t 13.746251 \t 6.791827 \t6.946405 \t 0.008018 \t 639.841836 s\n","966 \t 13.937164 \t 6.951296 \t6.977601 \t 0.008267 \t 640.492766 s\n","967 \t 13.950305 \t 6.938906 \t7.004696 \t 0.006704 \t 641.119179 s\n","968 \t 13.775763 \t 6.911815 \t6.855910 \t 0.008038 \t 641.731001 s\n","969 \t 13.809417 \t 6.847798 \t6.952594 \t 0.009024 \t 642.423656 s\n","970 \t 13.862199 \t 6.886149 \t6.965163 \t 0.010886 \t 643.003116 s\n","971 \t 13.853562 \t 6.864532 \t6.983505 \t 0.005525 \t 643.508272 s\n","972 \t 13.769153 \t 6.901465 \t6.858875 \t 0.008813 \t 644.014909 s\n","973 \t 13.777871 \t 6.820824 \t6.951208 \t 0.005838 \t 644.511056 s\n","974 \t 13.865899 \t 6.941253 \t6.920085 \t 0.004561 \t 645.138697 s\n","975 \t 13.823724 \t 6.841592 \t6.974641 \t 0.007491 \t 645.659311 s\n","976 \t 13.891011 \t 6.902566 \t6.982694 \t 0.005751 \t 646.166899 s\n","977 \t 13.776180 \t 6.888952 \t6.878981 \t 0.008246 \t 646.693083 s\n","978 \t 13.885255 \t 6.871175 \t7.006658 \t 0.007423 \t 647.200810 s\n","979 \t 13.802375 \t 6.933344 \t6.861375 \t 0.007657 \t 647.711646 s\n","980 \t 13.781637 \t 6.909844 \t6.866682 \t 0.005111 \t 648.220467 s\n","981 \t 13.865306 \t 6.809682 \t7.049056 \t 0.006568 \t 648.732009 s\n","982 \t 13.822819 \t 6.938161 \t6.877926 \t 0.006732 \t 649.236639 s\n","983 \t 13.870231 \t 6.852821 \t7.008028 \t 0.009381 \t 649.746454 s\n","984 \t 13.897090 \t 6.827806 \t7.058761 \t 0.010524 \t 650.385644 s\n","985 \t 13.897149 \t 6.938581 \t6.949887 \t 0.008682 \t 650.909308 s\n","986 \t 13.860467 \t 6.955576 \t6.896839 \t 0.008052 \t 651.413331 s\n","987 \t 13.988117 \t 6.963764 \t7.016311 \t 0.008042 \t 651.942009 s\n","988 \t 13.747950 \t 6.814297 \t6.927417 \t 0.006236 \t 652.448402 s\n","989 \t 13.673903 \t 6.739595 \t6.928938 \t 0.005370 \t 653.057008 s\n","990 \t 13.908422 \t 6.960804 \t6.941085 \t 0.006534 \t 653.679509 s\n","991 \t 13.885617 \t 6.955788 \t6.921789 \t 0.008040 \t 654.282396 s\n","992 \t 13.845712 \t 6.929810 \t6.909594 \t 0.006308 \t 654.938549 s\n","993 \t 13.911211 \t 6.943415 \t6.955710 \t 0.012086 \t 655.746725 s\n","994 \t 13.735534 \t 6.837661 \t6.891169 \t 0.006704 \t 656.255199 s\n","995 \t 13.727915 \t 6.870949 \t6.850534 \t 0.006433 \t 656.788888 s\n","996 \t 13.864098 \t 6.946257 \t6.909937 \t 0.007905 \t 657.293937 s\n","997 \t 13.746532 \t 6.847549 \t6.892721 \t 0.006261 \t 657.821455 s\n","998 \t 13.937109 \t 7.031431 \t6.899190 \t 0.006488 \t 658.323750 s\n","999 \t 13.877939 \t 6.843976 \t7.028725 \t 0.005238 \t 658.839443 s\n","1000 \t 13.838567 \t 6.966365 \t6.867226 \t 0.004976 \t 659.341453 s\n","1001 \t 13.889325 \t 6.938956 \t6.943130 \t 0.007238 \t 660.021708 s\n","1002 \t 13.850275 \t 6.960846 \t6.879492 \t 0.009937 \t 660.525288 s\n","1003 \t 13.891776 \t 6.861524 \t7.024580 \t 0.005671 \t 661.045858 s\n","1004 \t 14.004539 \t 6.989370 \t7.009280 \t 0.005888 \t 661.590887 s\n","1005 \t 13.827532 \t 6.878383 \t6.941402 \t 0.007747 \t 662.099610 s\n","1006 \t 13.840352 \t 6.869115 \t6.961303 \t 0.009935 \t 662.609088 s\n","1007 \t 14.056789 \t 6.992147 \t7.057455 \t 0.007187 \t 663.125608 s\n","1008 \t 13.854096 \t 6.848255 \t6.993434 \t 0.012407 \t 663.627192 s\n","1009 \t 13.902273 \t 6.895080 \t7.002233 \t 0.004960 \t 664.138283 s\n","1010 \t 13.807045 \t 6.828844 \t6.972236 \t 0.005965 \t 664.645687 s\n","1011 \t 13.861578 \t 6.879619 \t6.973880 \t 0.008080 \t 665.294273 s\n","1012 \t 13.730050 \t 6.771692 \t6.949365 \t 0.008993 \t 665.869140 s\n","1013 \t 13.860915 \t 6.890129 \t6.964149 \t 0.006636 \t 666.500522 s\n","1014 \t 13.749938 \t 6.812988 \t6.933118 \t 0.003831 \t 667.155241 s\n","1015 \t 13.853414 \t 6.925957 \t6.922783 \t 0.004674 \t 667.769379 s\n","1016 \t 13.956924 \t 6.930417 \t7.018629 \t 0.007878 \t 668.460785 s\n","1017 \t 13.870933 \t 6.871766 \t6.988247 \t 0.010919 \t 669.040153 s\n","1018 \t 13.747100 \t 6.859672 \t6.877371 \t 0.010058 \t 669.552626 s\n","1019 \t 13.861547 \t 6.819855 \t7.038054 \t 0.003638 \t 670.051816 s\n","1020 \t 13.777396 \t 6.828738 \t6.942560 \t 0.006097 \t 670.558419 s\n","1021 \t 13.882168 \t 6.961463 \t6.915760 \t 0.004945 \t 671.204737 s\n","1022 \t 13.961537 \t 6.896040 \t7.054005 \t 0.011492 \t 671.726099 s\n","1023 \t 13.799735 \t 6.833021 \t6.956996 \t 0.009719 \t 672.239642 s\n","1024 \t 13.920578 \t 6.938487 \t6.974846 \t 0.007246 \t 672.760411 s\n","1025 \t 13.813193 \t 6.895949 \t6.910536 \t 0.006708 \t 673.268566 s\n","1026 \t 13.664911 \t 6.740011 \t6.919966 \t 0.004934 \t 673.789466 s\n","1027 \t 13.746234 \t 6.801883 \t6.936435 \t 0.007916 \t 674.292821 s\n","1028 \t 13.771126 \t 6.837392 \t6.928475 \t 0.005258 \t 674.824409 s\n","1029 \t 13.877851 \t 6.985201 \t6.883746 \t 0.008905 \t 675.323966 s\n","1030 \t 13.927019 \t 6.921330 \t6.996964 \t 0.008725 \t 675.851182 s\n","1031 \t 13.825108 \t 6.841618 \t6.977134 \t 0.006357 \t 676.497514 s\n","1032 \t 13.799209 \t 6.940150 \t6.853029 \t 0.006031 \t 677.010743 s\n","1033 \t 13.786147 \t 6.884566 \t6.895431 \t 0.006150 \t 677.527201 s\n","1034 \t 13.669309 \t 6.822549 \t6.840036 \t 0.006724 \t 678.032999 s\n","1035 \t 13.895141 \t 6.891224 \t6.998397 \t 0.005520 \t 678.546667 s\n","1036 \t 13.932027 \t 6.928033 \t6.997836 \t 0.006158 \t 679.151468 s\n","1037 \t 13.798529 \t 6.840653 \t6.950064 \t 0.007812 \t 679.779692 s\n","1038 \t 13.751233 \t 6.837108 \t6.908401 \t 0.005724 \t 680.398909 s\n","1039 \t 13.709445 \t 6.877255 \t6.825155 \t 0.007035 \t 681.054252 s\n","1040 \t 13.926867 \t 6.894953 \t7.021189 \t 0.010726 \t 681.854341 s\n","1041 \t 13.913057 \t 6.897369 \t7.009368 \t 0.006320 \t 682.357714 s\n","1042 \t 13.817765 \t 6.799897 \t7.007882 \t 0.009986 \t 682.882256 s\n","1043 \t 13.869401 \t 6.818675 \t7.040265 \t 0.010461 \t 683.387381 s\n","1044 \t 13.898623 \t 6.871887 \t7.019187 \t 0.007548 \t 683.916100 s\n","1045 \t 13.778011 \t 6.899598 \t6.872120 \t 0.006293 \t 684.411481 s\n","1046 \t 13.790816 \t 6.906506 \t6.874937 \t 0.009373 \t 684.927318 s\n","1047 \t 13.749943 \t 6.868802 \t6.875378 \t 0.005763 \t 685.426824 s\n","1048 \t 13.870423 \t 6.969447 \t6.891019 \t 0.009958 \t 686.067744 s\n","1049 \t 13.833920 \t 6.917818 \t6.910142 \t 0.005960 \t 686.571331 s\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 162/162 [00:12<00:00, 13.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Link Prediction on Validation Set (Tri)\n","MRR: 0.3386\n","Hit@10: 0.4897\n","Hit@3: 0.3630\n","Hit@1: 0.2534\n","Link Prediction on Validation Set (All)\n","MRR: 0.3386\n","Hit@10: 0.4897\n","Hit@3: 0.3630\n","Hit@1: 0.2534\n","Relation Prediction on Validation Set (Tri)\n","MRR: 0.3466\n","Hit@10: 0.5864\n","Hit@3: 0.4877\n","Hit@1: 0.1728\n","Relation Prediction on Validation Set (All)\n","MRR: 0.3466\n","Hit@10: 0.5864\n","Hit@3: 0.4877\n","Hit@1: 0.1728\n","Numeric Value Prediction on Validation Set (Tri)\n","RMSE: 0.0589\n","Numeric Value Prediction on Validation Set (All)\n","RMSE: 0.0589\n"]}]},{"cell_type":"markdown","source":["# Test.py\n"],"metadata":{"id":"-BsiHiMQoArV"}},{"cell_type":"code","source":["KG = VTHNKG(args.data, max_vis_len = args.max_img_num, test = True)\n","\n","KG_DataLoader = torch.utils.data.DataLoader(KG, batch_size = args.batch_size ,shuffle = True)\n","\n","model = VTHN(\n","num_ent = KG.num_ent, # 엔티티 개수\n","num_rel = KG.num_rel, # relation 개수\n","## num_nv = KG.num_nv, # numeric value 개수 -> 필요 없음\n","## num_qual = KG.num_qual, # qualifier 개수 -> 필요 없음\n","ent_vis = KG.ent_vis_matrix.cuda(), # entity에 대한 visual feature\n","rel_vis = KG.rel_vis_matrix.cuda(), # relation에 대한 visual feature\n","dim_vis = KG.vis_feat_size, # visual feature의 dimension\n","ent_txt = KG.ent_txt_matrix.cuda(), # entity의 textual feature\n","rel_txt = KG.rel_txt_matrix.cuda(), # relation의 textual feature\n","dim_txt = KG.txt_feat_size, # textual feature의 dimension\n","ent_vis_mask = KG.ent_vis_mask.cuda(), # entity의 visual feature의 유무 판정 마스크\n","rel_vis_mask = KG.rel_vis_mask.cuda(), # relation의 visual feature의 유무 판정 마스크\n","dim_str = args.dim, # structual dimension(기본이 되는 차원)\n","num_head = args.num_head, # multihead 개수\n","dim_hid = args.hidden_dim, # ff layer hidden layer dimension\n","num_layer_enc_ent = args.num_layer_enc_ent, # entity encoder layer 개수\n","num_layer_enc_rel = args.num_layer_enc_rel, # relation encoder layer 개수\n","num_layer_prediction = args.num_layer_prediction, # prediction transformer layer 개수\n","num_layer_context = args.num_layer_context, # context transformer layer 개수\n","dropout = args.dropout, # transformer layer의 dropout\n","emb_dropout = args.emb_dropout, # structural embedding 생성에서의 dropout (structural 정보를 얼마나 버릴지 결정)\n","vis_dropout = args.vis_dropout, # visual embedding 생성에서의 dropout (visual 정보를 얼마나 버릴지 결정)\n","txt_dropout = args.txt_dropout, # textual embedding 생성에서의 dropout (textual 정보를 얼마나 버릴지 결정)\n","## max_qual = 5, # qualfier 최대 개수 (padding 때문에 필요) -> 이후의 batch_pad 계산 방식으로 인해 필요 없음.\n","emb_as_proj = False # 학습 효율성을 위한 조정\n",")\n","\n","model = model.cuda()\n","\n","model.load_state_dict(torch.load(f\"/content/drive/MyDrive/code/VTHNKG-OT/checkpoint/Reproduce/VTHNKG-OT/lr_0.0004_dim_256__1050.ckpt\")[\"model_state_dict\"])\n","\n","model.eval()\n","\n","lp_tri_list_rank = []  # 기본 triplet 링크 예측 순위 저장\n","lp_all_list_rank = []  # 모든 링크 예측(기본+확장) 순위 저장\n","rp_tri_list_rank = []  # 기본 triplet 관계 예측 순위 저장\n","rp_all_list_rank = []  # 모든 관계 예측 순위 저장\n","nvp_tri_se = 0         # 기본 triplet 숫자값 예측 제곱 오차 합\n","nvp_tri_se_num = 0     # 기본 triplet 숫자값 예측 횟수\n","nvp_all_se = 0         # 모든 숫자값 예측 제곱 오차 합\n","nvp_all_se_num = 0     # 모든 숫자값 예측 횟수\n","with torch.no_grad():\n","    for tri, tri_pad, tri_num in tqdm(zip(KG.test, KG.test_pad, KG.test_num), total = len(KG.test)):\n","        tri_len = len(tri)\n","        pad_idx = 0\n","        for ent_idx in range((tri_len+1)//2): # 총 엔티티 개수만큼큼\n","            # 패딩 확인\n","            if tri_pad[pad_idx]:\n","                break\n","            if ent_idx != 0:\n","                pad_idx += 1\n","\n","            # 테스트 트리플렛\n","            test_triplet = torch.tensor([tri])\n","\n","            # 마스킹 위치 설정\n","            mask_locs = torch.full((1,(KG.max_len-3)//2+1), False)\n","            if ent_idx < 2:\n","                mask_locs[0,0] = True\n","            else:\n","                mask_locs[0,ent_idx-1] = True\n","            if tri[ent_idx*2] >= KG.num_ent: # 숫자 예측 경우\n","                assert ent_idx != 0\n","                test_num = torch.tensor([tri_num])\n","                test_num[0,ent_idx-1] = -1\n","                # 숫자 마스킹 후 예측\n","                _,_,score_num = model(test_triplet.cuda(), test_num.cuda(), torch.tensor([tri_pad]).cuda(), mask_locs)\n","                score_num = score_num.detach().cpu().numpy()\n","                if ent_idx == 1: # triplet의 숫자\n","                    pred = score_num[0, 3, tri[ent_idx*2] - KG.num_ent]\n","                    gt = tri_num[ent_idx - 1]\n","                    sq_error = (pred - gt) ** 2\n","                    nvp_tri_se += sq_error\n","                    nvp_tri_se_num += 1\n","                    # ⭐️ 예측값 출력\n","                    print(f\"[Triplet Num] GT: {gt:.4f}, Pred: {pred:.4f}, SE: {sq_error:.6f}\")\n","                else: # qualifier\n","                    sq_error = (score_num[0,2,tri[ent_idx*2]-KG.num_ent] - tri_num[ent_idx-1])**2\n","                nvp_all_se += sq_error\n","                nvp_all_se_num += 1\n","            else: # 엔티티 예측\n","                test_triplet[0,2*ent_idx] = KG.num_ent+KG.num_rel # 사용되는 특수 마스크 토큰 (다른 엔티티와 겹치지 않음)\n","                filt_tri = copy.deepcopy(tri)\n","                filt_tri[ent_idx*2] = 2*(KG.num_ent+KG.num_rel)\n","                if ent_idx != 1 and filt_tri[2] >= KG.num_ent:\n","                    re_pair = [(filt_tri[0], filt_tri[1], filt_tri[1] * 2 + tri_num[0])] # 숫자자\n","                else:\n","                    re_pair = [(filt_tri[0], filt_tri[1], filt_tri[2])]\n","                for qual_idx,(q,v) in enumerate(zip(filt_tri[3::2], filt_tri[4::2])): # qualifier에 대해 반복복\n","                    if tri_pad[qual_idx+1]:\n","                        break\n","                    if ent_idx != qual_idx + 2 and v >= KG.num_ent:\n","                        re_pair.append((q, q*2 + tri_num[qual_idx + 1]))\n","                    else:\n","                        re_pair.append((q,v))\n","                re_pair.sort()\n","                filt = KG.filter_dict[tuple(re_pair)]\n","                score_ent, _, _ = model(test_triplet.cuda(), torch.tensor([tri_num]).cuda(), torch.tensor([tri_pad]).cuda(), mask_locs)\n","                score_ent = score_ent.detach().cpu().numpy()\n","                if ent_idx < 2:\n","                    rank = calculate_rank(score_ent[0,1+2*ent_idx],tri[ent_idx*2], filt)\n","                    lp_tri_list_rank.append(rank)\n","                else:\n","                    rank = calculate_rank(score_ent[0,2], tri[ent_idx*2], filt)\n","                lp_all_list_rank.append(rank)\n","        for rel_idx in range(tri_len//2): # 관계에 대한 예측\n","            if tri_pad[rel_idx]:\n","                break\n","            mask_locs = torch.full((1,(KG.max_len-3)//2+1), False)\n","            mask_locs[0,rel_idx] = True\n","            test_triplet = torch.tensor([tri])\n","            orig_rels = tri[1::2]\n","            test_triplet[0, rel_idx*2 + 1] = KG.num_rel\n","            if test_triplet[0, rel_idx*2+2] >= KG.num_ent: # 숫자값의 경우 특수 마스크 토큰큰\n","                test_triplet[0, rel_idx*2 + 2] = KG.num_ent + KG.num_rel\n","            filt_tri = copy.deepcopy(tri)\n","            # 필터링 및 scoring (entity와 동일)\n","            filt_tri[rel_idx*2+1] = 2*(KG.num_ent+KG.num_rel)\n","            if filt_tri[2] >= KG.num_ent:\n","                re_pair = [(filt_tri[0], filt_tri[1], orig_rels[0]*2 + tri_num[0])]\n","            else:\n","                re_pair = [(filt_tri[0], filt_tri[1], filt_tri[2])]\n","            for qual_idx,(q,v) in enumerate(zip(filt_tri[3::2], filt_tri[4::2])):\n","                if tri_pad[qual_idx+1]:\n","                    break\n","                if v >= KG.num_ent:\n","                    re_pair.append((q, orig_rels[qual_idx + 1]*2 + tri_num[qual_idx + 1]))\n","                else:\n","                    re_pair.append((q,v))\n","            re_pair.sort()\n","            filt = KG.filter_dict[tuple(re_pair)]\n","            _,score_rel, _ = model(test_triplet.cuda(), torch.tensor([tri_num]).cuda(), torch.tensor([tri_pad]).cuda(), mask_locs)\n","            score_rel = score_rel.detach().cpu().numpy()\n","            if rel_idx == 0:\n","                rank = calculate_rank(score_rel[0,2], tri[rel_idx*2+1], filt)\n","                rp_tri_list_rank.append(rank)\n","            else:\n","                rank = calculate_rank(score_rel[0,1], tri[rel_idx*2+1], filt)\n","            rp_all_list_rank.append(rank)\n","\n","lp_tri_list_rank = np.array(lp_tri_list_rank)\n","lp_tri_mrr, lp_tri_hit10, lp_tri_hit3, lp_tri_hit1 = metrics(lp_tri_list_rank)\n","print(\"Link Prediction on Validation Set (Tri)\")\n","print(f\"MRR: {lp_tri_mrr:.4f}\")\n","print(f\"Hit@10: {lp_tri_hit10:.4f}\")\n","print(f\"Hit@3: {lp_tri_hit3:.4f}\")\n","print(f\"Hit@1: {lp_tri_hit1:.4f}\")\n","\n","lp_all_list_rank = np.array(lp_all_list_rank)\n","lp_all_mrr, lp_all_hit10, lp_all_hit3, lp_all_hit1 = metrics(lp_all_list_rank)\n","print(\"Link Prediction on Validation Set (All)\")\n","print(f\"MRR: {lp_all_mrr:.4f}\")\n","print(f\"Hit@10: {lp_all_hit10:.4f}\")\n","print(f\"Hit@3: {lp_all_hit3:.4f}\")\n","print(f\"Hit@1: {lp_all_hit1:.4f}\")\n","\n","rp_tri_list_rank = np.array(rp_tri_list_rank)\n","rp_tri_mrr, rp_tri_hit10, rp_tri_hit3, rp_tri_hit1 = metrics(rp_tri_list_rank)\n","print(\"Relation Prediction on Validation Set (Tri)\")\n","print(f\"MRR: {rp_tri_mrr:.4f}\")\n","print(f\"Hit@10: {rp_tri_hit10:.4f}\")\n","print(f\"Hit@3: {rp_tri_hit3:.4f}\")\n","print(f\"Hit@1: {rp_tri_hit1:.4f}\")\n","\n","rp_all_list_rank = np.array(rp_all_list_rank)\n","rp_all_mrr, rp_all_hit10, rp_all_hit3, rp_all_hit1 = metrics(rp_all_list_rank)\n","print(\"Relation Prediction on Validation Set (All)\")\n","print(f\"MRR: {rp_all_mrr:.4f}\")\n","print(f\"Hit@10: {rp_all_hit10:.4f}\")\n","print(f\"Hit@3: {rp_all_hit3:.4f}\")\n","print(f\"Hit@1: {rp_all_hit1:.4f}\")\n","\n","if nvp_tri_se_num > 0:\n","    nvp_tri_rmse = math.sqrt(nvp_tri_se/nvp_tri_se_num)\n","    print(\"Numeric Value Prediction on Validation Set (Tri)\")\n","    print(f\"RMSE: {nvp_tri_rmse:.4f}\")\n","\n","if nvp_all_se_num > 0:\n","    nvp_all_rmse = math.sqrt(nvp_all_se/nvp_all_se_num)\n","    print(\"Numeric Value Prediction on Validation Set (All)\")\n","    print(f\"RMSE: {nvp_all_rmse:.4f}\")\n","\n"],"metadata":{"id":"ChVIC_5BHELi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747364666709,"user_tz":-540,"elapsed":16350,"user":{"displayName":"URP","userId":"16515248769931109428"}},"outputId":"07fec169-75bb-468c-8328-3aa893e99176"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stderr","text":[" 81%|████████  | 131/162 [00:10<00:02, 10.34it/s]"]},{"output_type":"stream","name":"stdout","text":["[Triplet Num] GT: 0.0000, Pred: -0.0002, SE: 0.000000\n","[Triplet Num] GT: 1.0000, Pred: 0.5938, SE: 0.165023\n"]},{"output_type":"stream","name":"stderr","text":["\r 82%|████████▏ | 133/162 [00:10<00:02, 10.08it/s]"]},{"output_type":"stream","name":"stdout","text":["[Triplet Num] GT: 0.0000, Pred: -0.0077, SE: 0.000059\n","[Triplet Num] GT: 0.0339, Pred: 0.0028, SE: 0.000967\n"]},{"output_type":"stream","name":"stderr","text":["\r 83%|████████▎ | 135/162 [00:10<00:02,  9.98it/s]"]},{"output_type":"stream","name":"stdout","text":["[Triplet Num] GT: 0.0195, Pred: 0.0663, SE: 0.002193\n","[Triplet Num] GT: 0.0000, Pred: -0.0161, SE: 0.000258\n","[Triplet Num] GT: 0.1525, Pred: 0.2451, SE: 0.008569\n"]},{"output_type":"stream","name":"stderr","text":[" 86%|████████▌ | 139/162 [00:10<00:02, 10.18it/s]"]},{"output_type":"stream","name":"stdout","text":["[Triplet Num] GT: 0.0322, Pred: -0.0040, SE: 0.001314\n","[Triplet Num] GT: 0.0000, Pred: 0.0731, SE: 0.005342\n","[Triplet Num] GT: 0.0000, Pred: -0.0146, SE: 0.000213\n"]},{"output_type":"stream","name":"stderr","text":[" 88%|████████▊ | 143/162 [00:11<00:01, 11.58it/s]"]},{"output_type":"stream","name":"stdout","text":["[Triplet Num] GT: 0.0000, Pred: 0.0419, SE: 0.001759\n","[Triplet Num] GT: 0.0000, Pred: -0.0041, SE: 0.000017\n","[Triplet Num] GT: 0.0025, Pred: 0.0162, SE: 0.000188\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|████████▉ | 145/162 [00:11<00:01, 12.11it/s]"]},{"output_type":"stream","name":"stdout","text":["[Triplet Num] GT: 0.0395, Pred: 0.0804, SE: 0.001675\n","[Triplet Num] GT: 0.0000, Pred: -0.0082, SE: 0.000068\n","[Triplet Num] GT: 0.0000, Pred: -0.0206, SE: 0.000426\n"]},{"output_type":"stream","name":"stderr","text":[" 92%|█████████▏| 149/162 [00:11<00:01, 12.83it/s]"]},{"output_type":"stream","name":"stdout","text":["[Triplet Num] GT: 0.0000, Pred: 0.1163, SE: 0.013515\n","[Triplet Num] GT: 0.0000, Pred: 0.0030, SE: 0.000009\n","[Triplet Num] GT: 0.0000, Pred: -0.0003, SE: 0.000000\n"]},{"output_type":"stream","name":"stderr","text":["\r 93%|█████████▎| 151/162 [00:11<00:00, 13.09it/s]"]},{"output_type":"stream","name":"stdout","text":["[Triplet Num] GT: 0.0000, Pred: 0.0350, SE: 0.001228\n","[Triplet Num] GT: 0.0000, Pred: 0.0043, SE: 0.000019\n","[Triplet Num] GT: 0.0000, Pred: 0.0084, SE: 0.000070\n"]},{"output_type":"stream","name":"stderr","text":[" 96%|█████████▌| 155/162 [00:12<00:00, 13.57it/s]"]},{"output_type":"stream","name":"stdout","text":["[Triplet Num] GT: 0.0000, Pred: -0.0037, SE: 0.000014\n","[Triplet Num] GT: 0.0395, Pred: 0.0510, SE: 0.000133\n","[Triplet Num] GT: 1.0000, Pred: 0.8495, SE: 0.022643\n"]},{"output_type":"stream","name":"stderr","text":["\r 97%|█████████▋| 157/162 [00:12<00:00, 13.38it/s]"]},{"output_type":"stream","name":"stdout","text":["[Triplet Num] GT: 0.0000, Pred: -0.0131, SE: 0.000173\n","[Triplet Num] GT: 0.1206, Pred: 0.0872, SE: 0.001113\n","[Triplet Num] GT: 0.0195, Pred: 0.0249, SE: 0.000030\n"]},{"output_type":"stream","name":"stderr","text":[" 99%|█████████▉| 161/162 [00:12<00:00, 13.61it/s]"]},{"output_type":"stream","name":"stdout","text":["[Triplet Num] GT: 0.0015, Pred: 0.0492, SE: 0.002275\n","[Triplet Num] GT: 1.0000, Pred: 0.3185, SE: 0.464502\n","[Triplet Num] GT: 0.0000, Pred: 0.1379, SE: 0.019007\n"]},{"output_type":"stream","name":"stderr","text":["\r100%|██████████| 162/162 [00:12<00:00, 12.90it/s]"]},{"output_type":"stream","name":"stdout","text":["[Triplet Num] GT: 0.0345, Pred: 0.1197, SE: 0.007250\n","Link Prediction on Validation Set (Tri)\n","MRR: 0.3614\n","Hit@10: 0.4863\n","Hit@3: 0.3733\n","Hit@1: 0.2945\n","Link Prediction on Validation Set (All)\n","MRR: 0.3614\n","Hit@10: 0.4863\n","Hit@3: 0.3733\n","Hit@1: 0.2945\n","Relation Prediction on Validation Set (Tri)\n","MRR: 0.3418\n","Hit@10: 0.6111\n","Hit@3: 0.4877\n","Hit@1: 0.1667\n","Relation Prediction on Validation Set (All)\n","MRR: 0.3418\n","Hit@10: 0.6111\n","Hit@3: 0.4877\n","Hit@1: 0.1667\n","Numeric Value Prediction on Validation Set (Tri)\n","RMSE: 0.1500\n","Numeric Value Prediction on Validation Set (All)\n","RMSE: 0.1500\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]}]}